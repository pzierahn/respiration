{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extract Signal with EfficientPhys\n",
    "\n",
    "This notebook demonstrates how to extract a signal from a video using the EfficientPhys model. The pretrained models extract rPPG signals from a video. The fine-tuned are trained to extract the respiratory signals."
   ],
   "id": "3baa6d5159abc725"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "\n",
    "subject = 'Proband16'\n",
    "setting = '101_natural_lighting'\n",
    "\n",
    "frames, meta = dataset.get_video_rgb(\n",
    "    subject,\n",
    "    setting,\n",
    "    num_frames=30 * 12,\n",
    "    show_progress=True,\n",
    ")"
   ],
   "id": "a61011c940742495",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import respiration.utils as utils\n",
    "from respiration.extractor.efficient_phys import EfficientPhys\n",
    "\n",
    "dim = 72\n",
    "frame_depth = 20\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "\n",
    "model = EfficientPhys(img_size=dim, frame_depth=frame_depth)\n",
    "\n",
    "# Wrap model in nn.DataParallel to fix model loading and key matching\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "model_checkpoint = os.path.join('..', '..', 'data', 'rPPG-Toolbox', 'BP4D_PseudoLabel_EfficientPhys.pth')\n",
    "key_matching = model.load_state_dict(torch.load(model_checkpoint, map_location=device))"
   ],
   "id": "c4dc5f528d1e36c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The model expects the input to be a multiple of the frame depth\n",
    "chunk_size = (frames.shape[0] // frame_depth) * frame_depth - (frame_depth - 1)\n",
    "frames_chunk = frames[:chunk_size]\n",
    "\n",
    "frames_chunk = utils.down_sample_video(frames_chunk, dim)"
   ],
   "id": "d5519669a6e5d716",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure_dir = utils.dir_path('outputs', 'figures', 'pre-process', mkdir=True)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(frames_chunk[0])\n",
    "\n",
    "utils.savefig(plt.gcf(), figure_dir, 'efficient_phys')"
   ],
   "id": "145f3d8e459688d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frames_chunk = torch.tensor(frames_chunk, dtype=torch.float32, device=device)\n",
    "\n",
    "# Permute from (T, H, W, C) to (T, C, H, W)\n",
    "frames_chunk = frames_chunk.permute(0, 3, 1, 2)"
   ],
   "id": "eb1efff9deba6f4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    out = model(frames_chunk)\n",
    "\n",
    "prediction = out.cpu().detach().numpy().squeeze()"
   ],
   "id": "732ea4ed2896ad42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.analysis as analysis\n",
    "\n",
    "respiration_gt = dataset.get_breathing_signal(subject, setting)\n",
    "\n",
    "# Cut to the same length as the video\n",
    "respiration_gt = respiration_gt[:prediction.shape[0]]\n",
    "\n",
    "compare = analysis.SignalComparator(\n",
    "    prediction,\n",
    "    respiration_gt,\n",
    "    meta.fps,\n",
    ")"
   ],
   "id": "2517ce634c55d72c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "compare.errors()",
   "id": "4c495e90724964ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "compare.signal_distances()",
   "id": "4e7b99ca805f825e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.figure(figsize=(20, 5))\n",
    "plt.plot(compare.prediction, label='Prediction')\n",
    "plt.plot(compare.ground_truth, label='Ground Truth')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "bbc1d611be8cac33",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
