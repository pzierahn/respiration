{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluate the performance of the different models by using a sliding window approach\n",
    "\n",
    "Steps:\n",
    "1. Harmonize the predictions to have the same format\n",
    "2. Extract the frequencies using a sliding window approach\n",
    "3. Evaluate the performance of the models\n",
    "4. Visualize the results"
   ],
   "id": "858d2eaef54d2b36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 1: Harmonize the predictions",
   "id": "d5de492f4255dbcf"
  },
  {
   "cell_type": "code",
   "id": "db3bfc6b2e01322a",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import respiration.utils as utils\n",
    "\n",
    "signals_dir = utils.dir_path('outputs', 'signals')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raft_file = utils.join_paths(signals_dir, 'raft_predictions.csv')\n",
    "raft_predictions = pd.read_csv(raft_file)\n",
    "raft_predictions['signal'] = raft_predictions['signal_v'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the chest roi predictions\n",
    "raft_predictions = raft_predictions[raft_predictions['roi'] == 'chest']\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "raft_predictions = raft_predictions[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "raft_predictions.head()"
   ],
   "id": "9e7ad8144746a824",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flownet_file = utils.join_paths(signals_dir, 'flownet_predictions.csv')\n",
    "flownet_predictions = pd.read_csv(flownet_file)\n",
    "flownet_predictions['signal'] = flownet_predictions['signal_v'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the chest roi predictions\n",
    "flownet_predictions = flownet_predictions[flownet_predictions['roi'] == 'chest']\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "flownet_predictions = flownet_predictions[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "flownet_predictions.head()"
   ],
   "id": "2a413445397940c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pretrained_file = utils.join_paths(signals_dir, 'pretrained_predictions.csv')\n",
    "pretrained_predictions = pd.read_csv(pretrained_file)\n",
    "pretrained_predictions['signal'] = pretrained_predictions['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "pretrained_predictions = pretrained_predictions[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "pretrained_predictions.head()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unsupervised_file = utils.join_paths(signals_dir, 'unsupervised_predictions.csv')\n",
    "unsupervised_predictions = pd.read_csv(unsupervised_file)\n",
    "unsupervised_predictions['signal'] = unsupervised_predictions['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the chest roi predictions\n",
    "unsupervised_predictions = unsupervised_predictions[unsupervised_predictions['roi'] == 'chest']\n",
    "\n",
    "# Rename column method to model\n",
    "unsupervised_predictions.rename(columns={'method': 'model'}, inplace=True)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "unsupervised_predictions = unsupervised_predictions[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "unsupervised_predictions.head()"
   ],
   "id": "f995d2bcc90e1731",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fine_tuned_path = utils.join_paths(signals_dir, 'fine_tuned_predictions.csv')\n",
    "\n",
    "fine_tuned_prediction = pd.read_csv(fine_tuned_path)\n",
    "fine_tuned_prediction['signal'] = fine_tuned_prediction['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "fine_tuned_prediction = fine_tuned_prediction[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "fine_tuned_prediction.head()"
   ],
   "id": "a2a9483fb4990ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "r_ppg_path = utils.join_paths(signals_dir, 'r_ppg_predictions.csv')\n",
    "\n",
    "r_ppg_prediction = pd.read_csv(r_ppg_path)\n",
    "r_ppg_prediction['signal'] = r_ppg_prediction['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "r_ppg_prediction = r_ppg_prediction[['subject', 'setting', 'model', 'signal']]\n",
    "r_ppg_prediction.head()"
   ],
   "id": "d4fba7688e368e8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transformer_path = utils.join_paths(signals_dir, 'transformer_predictions.csv')\n",
    "\n",
    "transformer_prediction = pd.read_csv(transformer_path)\n",
    "transformer_prediction['signal'] = transformer_prediction['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Add a tf_ prefix to the model names\n",
    "transformer_prediction['model'] = 'tf_' + transformer_prediction['model']\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "transformer_prediction = transformer_prediction[['subject', 'setting', 'model', 'signal']]\n",
    "transformer_prediction.head()"
   ],
   "id": "3ff4d484569eeff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# The random signal is used as a baseline to see how well the models perform against a random predictions\n",
    "#\n",
    "random_path = utils.join_paths(signals_dir, 'random_predictions.csv')\n",
    "\n",
    "random_prediction = pd.read_csv(random_path)\n",
    "random_prediction['signal'] = random_prediction['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "random_prediction = random_prediction[['subject', 'setting', 'model', 'signal']]\n",
    "random_prediction.head()"
   ],
   "id": "c980aed7c7a98e46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = pd.concat([\n",
    "    raft_predictions,\n",
    "    flownet_predictions,\n",
    "    pretrained_predictions,\n",
    "    unsupervised_predictions,\n",
    "    fine_tuned_prediction,\n",
    "    r_ppg_prediction,\n",
    "    transformer_prediction,\n",
    "    random_prediction,\n",
    "])\n",
    "len(predictions)"
   ],
   "id": "26fd22df832dffa8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2: Extract the frequencies using a sliding window approach",
   "id": "37e70d5e3a50c222"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()"
   ],
   "id": "42dfbd471b70b5f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import respiration.analysis as analysis\n",
    "\n",
    "# rPPG lowpass and highpass frequencies\n",
    "# lowpass = 0.7\n",
    "# highpass = 2.5\n",
    "\n",
    "# Breathing lowpass and highpass frequencies\n",
    "lowpass = 0.08\n",
    "highpass = 0.5\n",
    "\n",
    "subjects = predictions['subject'].unique()\n",
    "settings = predictions['setting'].unique()\n",
    "\n",
    "frequency_predictions = []\n",
    "distances = []\n",
    "\n",
    "for (subject, setting) in tqdm(itertools.product(subjects, settings), total=len(subjects) * len(settings)):\n",
    "    scenario_predictions = predictions[\n",
    "        (predictions['subject'] == subject) &\n",
    "        (predictions['setting'] == setting)]\n",
    "\n",
    "    if len(scenario_predictions) == 0:\n",
    "        continue\n",
    "\n",
    "    # Get the ground truth signal\n",
    "    gt_signal = dataset.get_breathing_signal(subject, setting)\n",
    "\n",
    "    for model in scenario_predictions['model'].unique():\n",
    "        model_scenario_predictions = scenario_predictions[scenario_predictions['model'] == model]\n",
    "        predicted_signal = model_scenario_predictions['signal'].values[0]\n",
    "        pred_frequencies = analysis.sliding_window_analysis(predicted_signal, 30, lowpass, highpass)\n",
    "\n",
    "        min_length = min(len(predicted_signal), len(gt_signal))\n",
    "\n",
    "        gt_signal_cut = gt_signal[:min_length]\n",
    "        gt_frequencies = analysis.sliding_window_analysis(gt_signal_cut, 30, lowpass, highpass)\n",
    "\n",
    "        for metric in gt_frequencies:\n",
    "            frequency_predictions.append({\n",
    "                'subject': subject,\n",
    "                'setting': setting,\n",
    "                'model': model,\n",
    "                'metric': metric,\n",
    "                'gt_frequencies': gt_frequencies[metric],\n",
    "                'pred_frequencies': pred_frequencies[metric]\n",
    "            })\n",
    "\n",
    "        compare = analysis.SignalComparator(\n",
    "            gt_signal_cut,\n",
    "            predicted_signal,\n",
    "            30,\n",
    "            lowpass=lowpass,\n",
    "            highpass=highpass,\n",
    "        )\n",
    "        signal_distances = compare.signal_distances()\n",
    "        for metric in signal_distances:\n",
    "            distances.append({\n",
    "                'subject': subject,\n",
    "                'setting': setting,\n",
    "                'model': model,\n",
    "                'metric': metric,\n",
    "                'distance': signal_distances[metric]\n",
    "            })"
   ],
   "id": "182a18fc797f0313",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frequencies_df = pd.DataFrame(frequency_predictions)\n",
    "distances_df = pd.DataFrame(distances)\n",
    "\n",
    "# Take the absolute value of the distances\n",
    "distances_df['distance'] = distances_df['distance'].apply(np.abs)"
   ],
   "id": "df7df7d8702b3ac1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "analysis_dir = utils.dir_path('outputs', 'analysis')\n",
    "frequencies_path = utils.join_paths(analysis_dir, 'frequencies.csv')\n",
    "frequencies_df.to_csv(frequencies_path, index=False)\n",
    "\n",
    "distances_path = utils.join_paths(analysis_dir, 'distances.csv')\n",
    "distances_df.to_csv(distances_path, index=False)"
   ],
   "id": "78649f30186c2fa4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3: Average the frequencies and distances",
   "id": "e1be30a8fb719baa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "models = frequencies_df['model'].unique()\n",
    "metrics = frequencies_df['metric'].unique()\n",
    "\n",
    "evaluation_frequency = []\n",
    "\n",
    "for (model, metric) in itertools.product(models, metrics):\n",
    "    model_metric_df = frequencies_df[\n",
    "        (frequencies_df['model'] == model) &\n",
    "        (frequencies_df['metric'] == metric)]\n",
    "\n",
    "    # Concatenate the predicted and ground truth frequencies\n",
    "    gt_frequencies = np.concatenate(model_metric_df['gt_frequencies'].values)\n",
    "    pred_frequencies = np.concatenate(model_metric_df['pred_frequencies'].values)\n",
    "    gt_frequencies = gt_frequencies[:len(pred_frequencies)]\n",
    "\n",
    "    # Multiply the frequencies by 60 to get the bpm\n",
    "    gt_frequencies *= 60\n",
    "    pred_frequencies *= 60\n",
    "\n",
    "    mae = np.mean(np.abs(gt_frequencies - pred_frequencies))\n",
    "    rmse = np.sqrt(np.mean((gt_frequencies - pred_frequencies) ** 2))\n",
    "\n",
    "    corr, p = stats.pearsonr(gt_frequencies.flatten(), pred_frequencies.flatten())\n",
    "\n",
    "    evaluation_frequency.append({\n",
    "        'model': model,\n",
    "        'metric': metric,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'corr': corr,\n",
    "        'p': p\n",
    "    })"
   ],
   "id": "b85dff073044f9b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evaluation_df = pd.DataFrame(evaluation_frequency)\n",
    "evaluation_path = utils.join_paths(analysis_dir, 'frequency_evaluation.csv')\n",
    "evaluation_df.to_csv(evaluation_path, index=False)"
   ],
   "id": "44dbfc28b63961db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "models = distances_df['model'].unique()\n",
    "metrics = distances_df['metric'].unique()\n",
    "\n",
    "evaluation_distance = []\n",
    "\n",
    "for (model, metric) in itertools.product(models, metrics):\n",
    "    model_metric_df = distances_df[\n",
    "        (distances_df['model'] == model) &\n",
    "        (distances_df['metric'] == metric)]\n",
    "\n",
    "    mean = model_metric_df['distance'].mean()\n",
    "\n",
    "    evaluation_distance.append({\n",
    "        'model': model,\n",
    "        'metric': metric,\n",
    "        'mean': mean,\n",
    "    })"
   ],
   "id": "33deefa70c2e4c04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evaluation_distance_df = pd.DataFrame(evaluation_distance)\n",
    "evaluation_distance_path = utils.join_paths(analysis_dir, 'distance_evaluation.csv')\n",
    "evaluation_distance_df.to_csv(evaluation_distance_path, index=False)"
   ],
   "id": "7541e1d36ca648e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
