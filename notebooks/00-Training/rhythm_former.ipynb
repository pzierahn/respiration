{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train Rhythm Former\n",
    "\n",
    "This notebook trains and fine-tunes the Rhythm Former model on the VitalCam dataset."
   ],
   "id": "4c8a3ac7b2973e9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:47:03.718295Z",
     "start_time": "2024-07-19T12:47:03.715705Z"
    }
   },
   "cell_type": "code",
   "source": "manifest = {}",
   "id": "b5b5aa78287b1cdf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:47:05.511802Z",
     "start_time": "2024-07-19T12:47:03.718788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import respiration.utils as utils\n",
    "from respiration.dataset import (\n",
    "    VitalCamSet,\n",
    "    VitalCamLoader,\n",
    ")\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "scenarios_all = dataset.get_scenarios(['303_normalized_face'])\n",
    "\n",
    "split_ratio = 0.8\n",
    "manifest['split_ratio'] = split_ratio\n",
    "\n",
    "training = scenarios_all[:int(len(scenarios_all) * split_ratio)]\n",
    "manifest['training_scenarios'] = training\n",
    "\n",
    "testing = scenarios_all[int(len(scenarios_all) * split_ratio):]\n",
    "manifest['testing_scenarios'] = testing\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "manifest['device'] = device"
   ],
   "id": "a986fa7a5e5415b7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:47:05.515336Z",
     "start_time": "2024-07-19T12:47:05.512380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def preprocess_frames(frames):\n",
    "    # Preprocess the frames to be in 128x128 with torch\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(mode='RGB'),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Transform each frame\n",
    "    transformed_frames = torch.stack([\n",
    "        transform(frame) for frame in frames\n",
    "    ])\n",
    "\n",
    "    return transformed_frames.unsqueeze(0).to(device)"
   ],
   "id": "ad438dcfe2b366f7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-19T12:47:05.519393Z",
     "start_time": "2024-07-19T12:47:05.516020Z"
    }
   },
   "source": [
    "model_mmpd = utils.file_path('data', 'rhythm_former', 'MMPD_intra_RhythmFormer.pth')\n",
    "model_pure = utils.file_path('data', 'rhythm_former', 'PURE_cross_RhythmFormer.pth')\n",
    "model_ubfc = utils.file_path('data', 'rhythm_former', 'UBFC_cross_RhythmFormer.pth')\n",
    "\n",
    "models = {\n",
    "    'RhythmFormer': None,\n",
    "    'RhythmFormer_MMPD': model_mmpd,\n",
    "    'RhythmFormer_PURE': model_pure,\n",
    "    'RhythmFormer_UBFC': model_ubfc,\n",
    "}\n",
    "manifest['models'] = models"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:47:05.535363Z",
     "start_time": "2024-07-19T12:47:05.519967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import scipy\n",
    "from scipy.signal import butter, welch\n",
    "from scipy.sparse import spdiags\n",
    "\n",
    "\n",
    "def get_hr(y, sr=30, min=45, max=150):\n",
    "    p, q = welch(y, sr, nfft=1e5 / sr, nperseg=np.min((len(y) - 1, 256)))\n",
    "    return p[(p > min / 60) & (p < max / 60)][np.argmax(q[(p > min / 60) & (p < max / 60)])] * 60\n",
    "\n",
    "\n",
    "def get_psd(y, sr=30, min=45, max=150):\n",
    "    p, q = welch(y, sr, nfft=1e5 / sr, nperseg=np.min((len(y) - 1, 256)))\n",
    "    return q[(p > min / 60) & (p < max / 60)]\n",
    "\n",
    "\n",
    "def normal_sampling(mean, label_k, std):\n",
    "    return math.exp(-(label_k - mean) ** 2 / (2 * std ** 2)) / (math.sqrt(2 * math.pi) * std)\n",
    "\n",
    "\n",
    "def kl_loss(inputs, labels):\n",
    "    criterion = nn.KLDivLoss(reduce=False)\n",
    "    outputs = torch.log(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    #loss = loss.sum()/loss.shape[0]\n",
    "    loss = loss.sum()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def _detrend(input_signal, lambda_value):\n",
    "    \"\"\"Detrend PPG signal.\"\"\"\n",
    "    signal_length = input_signal.shape[0]\n",
    "    # observation matrix\n",
    "    H = np.identity(signal_length)\n",
    "    ones = np.ones(signal_length)\n",
    "    minus_twos = -2 * np.ones(signal_length)\n",
    "    diags_data = np.array([ones, minus_twos, ones])\n",
    "    diags_index = np.array([0, 1, 2])\n",
    "    D = spdiags(diags_data, diags_index,\n",
    "                (signal_length - 2), signal_length).toarray()\n",
    "    detrended_signal = np.dot(\n",
    "        (H - np.linalg.inv(H + (lambda_value ** 2) * np.dot(D.T, D))), input_signal)\n",
    "    return detrended_signal\n",
    "\n",
    "\n",
    "def calculate_hr(predictions, labels, fs=30, diff_flag=False):\n",
    "    \"\"\"Calculate video-level HR and SNR\"\"\"\n",
    "    if diff_flag:  # if the predictions and labels are 1st derivative of PPG signal.\n",
    "        predictions = _detrend(np.cumsum(predictions), 100)\n",
    "        labels = _detrend(np.cumsum(labels), 100)\n",
    "    else:\n",
    "        predictions = _detrend(predictions, 100)\n",
    "        labels = _detrend(labels, 100)\n",
    "    [b, a] = butter(1, [0.75 / fs * 2, 2.5 / fs * 2], btype='bandpass')\n",
    "    predictions = scipy.signal.filtfilt(b, a, np.double(predictions))\n",
    "    labels = scipy.signal.filtfilt(b, a, np.double(labels))\n",
    "    hr_pred = get_hr(predictions, sr=fs)\n",
    "    hr_label = get_hr(labels, sr=fs)\n",
    "    return hr_pred, hr_label\n",
    "\n",
    "\n",
    "def calculate_psd(predictions, labels, fs=30, diff_flag=False):\n",
    "    \"\"\"Calculate video-level HR and SNR\"\"\"\n",
    "    if diff_flag:  # if the predictions and labels are 1st derivative of PPG signal.\n",
    "        predictions = _detrend(np.cumsum(predictions), 100)\n",
    "        labels = _detrend(np.cumsum(labels), 100)\n",
    "    else:\n",
    "        predictions = _detrend(predictions, 100)\n",
    "        labels = _detrend(labels, 100)\n",
    "    [b, a] = butter(1, [0.75 / fs * 2, 2.5 / fs * 2], btype='bandpass')\n",
    "    predictions = scipy.signal.filtfilt(b, a, np.double(predictions))\n",
    "    labels = scipy.signal.filtfilt(b, a, np.double(labels))\n",
    "    psd_pred = get_psd(predictions, sr=fs)\n",
    "    psd_label = get_psd(labels, sr=fs)\n",
    "    return psd_pred, psd_label\n",
    "\n",
    "\n",
    "class TorchLossComputer(object):\n",
    "    @staticmethod\n",
    "    def compute_complex_absolute_given_k(output, k, N):\n",
    "        two_pi_n_over_N = Variable(2 * math.pi * torch.arange(0, N, dtype=torch.float), requires_grad=True) / N\n",
    "        hanning = Variable(torch.from_numpy(np.hanning(N)).type(torch.FloatTensor), requires_grad=True).view(1, -1)\n",
    "\n",
    "        k = k.type(torch.FloatTensor).cuda()\n",
    "        two_pi_n_over_N = two_pi_n_over_N.cuda()\n",
    "        hanning = hanning.cuda()\n",
    "\n",
    "        output = output.view(1, -1) * hanning\n",
    "        output = output.view(1, 1, -1).type(torch.cuda.FloatTensor)\n",
    "        k = k.view(1, -1, 1)\n",
    "        two_pi_n_over_N = two_pi_n_over_N.view(1, 1, -1)\n",
    "        complex_absolute = torch.sum(output * torch.sin(k * two_pi_n_over_N), dim=-1) ** 2 \\\n",
    "                           + torch.sum(output * torch.cos(k * two_pi_n_over_N), dim=-1) ** 2\n",
    "\n",
    "        return complex_absolute\n",
    "\n",
    "    @staticmethod\n",
    "    def complex_absolute(output, Fs, bpm_range=None):\n",
    "        output = output.view(1, -1)\n",
    "\n",
    "        N = output.size()[1]\n",
    "\n",
    "        unit_per_hz = Fs / N\n",
    "        feasible_bpm = bpm_range / 60.0\n",
    "        k = feasible_bpm / unit_per_hz\n",
    "\n",
    "        # only calculate feasible PSD range [0.7,4]Hz\n",
    "        complex_absolute = TorchLossComputer.compute_complex_absolute_given_k(output, k, N)\n",
    "\n",
    "        return (1.0 / complex_absolute.sum()) * complex_absolute  # Analogous Softmax operator\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_power_spectrum_loss(inputs, target, Fs):\n",
    "        inputs = inputs.view(1, -1)\n",
    "        target = target.view(1, -1)\n",
    "        bpm_range = torch.arange(40, 180, dtype=torch.float).cuda()\n",
    "        #bpm_range = torch.arange(40, 260, dtype=torch.float).cuda()\n",
    "\n",
    "        complex_absolute = TorchLossComputer.complex_absolute(inputs, Fs, bpm_range)\n",
    "\n",
    "        whole_max_val, whole_max_idx = complex_absolute.view(-1).max(0)\n",
    "        whole_max_idx = whole_max_idx.type(torch.float)\n",
    "\n",
    "        #pdb.set_trace()\n",
    "\n",
    "        #return F.cross_entropy(complex_absolute, target.view((1)).type(torch.long)).view(1),  (target.item() - whole_max_idx.item()) ** 2\n",
    "        return F.cross_entropy(complex_absolute, target.view((1)).type(torch.long)), torch.abs(\n",
    "            target[0] - whole_max_idx)\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_power_spectrum_focal_loss(inputs, target, Fs, gamma):\n",
    "        inputs = inputs.view(1, -1)\n",
    "        target = target.view(1, -1)\n",
    "        bpm_range = torch.arange(40, 180, dtype=torch.float).cuda()\n",
    "        #bpm_range = torch.arange(40, 260, dtype=torch.float).cuda()\n",
    "\n",
    "        complex_absolute = TorchLossComputer.complex_absolute(inputs, Fs, bpm_range)\n",
    "\n",
    "        whole_max_val, whole_max_idx = complex_absolute.view(-1).max(0)\n",
    "        whole_max_idx = whole_max_idx.type(torch.float)\n",
    "\n",
    "        #pdb.set_trace()\n",
    "        criterion = FocalLoss(gamma=gamma)\n",
    "\n",
    "        #return F.cross_entropy(complex_absolute, target.view((1)).type(torch.long)).view(1),  (target.item() - whole_max_idx.item()) ** 2\n",
    "        return criterion(complex_absolute, target.view((1)).type(torch.long)), torch.abs(target[0] - whole_max_idx)\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_power_spectrum_forward_pred(inputs, Fs):\n",
    "        inputs = inputs.view(1, -1)\n",
    "        bpm_range = torch.arange(40, 190, dtype=torch.float).cuda()\n",
    "        #bpm_range = torch.arange(40, 180, dtype=torch.float).cuda()\n",
    "        #bpm_range = torch.arange(40, 260, dtype=torch.float).cuda()\n",
    "\n",
    "        complex_absolute = TorchLossComputer.complex_absolute(inputs, Fs, bpm_range)\n",
    "\n",
    "        whole_max_val, whole_max_idx = complex_absolute.view(-1).max(0)\n",
    "        whole_max_idx = whole_max_idx.type(torch.float)\n",
    "\n",
    "        return whole_max_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def Frequency_loss(inputs, target, diff_flag, Fs, std):\n",
    "        hr_pred, hr_gt = calculate_hr(inputs.detach().cpu(), target.detach().cpu(), diff_flag=diff_flag, fs=Fs)\n",
    "        inputs = inputs.view(1, -1)\n",
    "        target = target.view(1, -1)\n",
    "        bpm_range = torch.arange(45, 150, dtype=torch.float).to(torch.device('cuda'))\n",
    "        ca = TorchLossComputer.complex_absolute(inputs, Fs, bpm_range)\n",
    "        sa = ca / torch.sum(ca)\n",
    "\n",
    "        target_distribution = [normal_sampling(int(hr_gt), i, std) for i in range(45, 150)]\n",
    "        target_distribution = [i if i > 1e-15 else 1e-15 for i in target_distribution]\n",
    "        target_distribution = torch.Tensor(target_distribution).to(torch.device('cuda'))\n",
    "\n",
    "        hr_gt = torch.tensor(hr_gt - 45).view(1).type(torch.long).to(torch.device('cuda'))\n",
    "        return F.cross_entropy(ca, hr_gt), kl_loss(sa, target_distribution)\n",
    "\n",
    "    @staticmethod\n",
    "    def HR_loss(inputs, target, diff_flag, Fs, std):\n",
    "        psd_pred, psd_gt = calculate_psd(inputs.detach().cpu(), target.detach().cpu(), diff_flag=diff_flag, fs=Fs)\n",
    "        pred_distribution = [normal_sampling(np.argmax(psd_pred), i, std) for i in range(psd_pred.size)]\n",
    "        pred_distribution = [i if i > 1e-15 else 1e-15 for i in pred_distribution]\n",
    "        pred_distribution = torch.Tensor(pred_distribution).to(torch.device('cuda'))\n",
    "        target_distribution = [normal_sampling(np.argmax(psd_gt), i, std) for i in range(psd_gt.size)]\n",
    "        target_distribution = [i if i > 1e-15 else 1e-15 for i in target_distribution]\n",
    "        target_distribution = torch.Tensor(target_distribution).to(torch.device('cuda'))\n",
    "        return kl_loss(pred_distribution, target_distribution)\n",
    "\n",
    "\n",
    "class Neg_Pearson(nn.Module):  # Pearson range [-1, 1] so if < 0, abs|loss| ; if >0, 1- loss\n",
    "    def __init__(self):\n",
    "        super(Neg_Pearson, self).__init__()\n",
    "\n",
    "    def forward(self, preds, labels):  # all variable operation\n",
    "        loss = 0\n",
    "        for i in range(preds.shape[0]):\n",
    "            sum_x = torch.sum(preds[i])  # x\n",
    "            sum_y = torch.sum(labels[i])  # y\n",
    "            sum_xy = torch.sum(preds[i] * labels[i])  # xy\n",
    "            sum_x2 = torch.sum(torch.pow(preds[i], 2))  # x^2\n",
    "            sum_y2 = torch.sum(torch.pow(labels[i], 2))  # y^2\n",
    "            N = preds.shape[1]\n",
    "            pearson = (N * sum_xy - sum_x * sum_y) / (\n",
    "                torch.sqrt((N * sum_x2 - torch.pow(sum_x, 2)) * (N * sum_y2 - torch.pow(sum_y, 2))))\n",
    "            loss += 1 - pearson\n",
    "\n",
    "        loss = loss / preds.shape[0]\n",
    "        return loss\n",
    "\n",
    "\n",
    "class RhythmFormer_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RhythmFormer_Loss, self).__init__()\n",
    "        self.criterion_Pearson = Neg_Pearson()\n",
    "\n",
    "    def forward(self, pred_ppg, labels, epoch, FS, diff_flag):\n",
    "        loss_time = self.criterion_Pearson(pred_ppg.view(1, -1), labels.view(1, -1))\n",
    "        loss_CE, loss_distribution_kl = TorchLossComputer.Frequency_loss(\n",
    "            pred_ppg.squeeze(-1),\n",
    "            labels.squeeze(-1),\n",
    "            diff_flag=diff_flag,\n",
    "            Fs=FS,\n",
    "            std=3.0)\n",
    "        loss_hr = TorchLossComputer.HR_loss(\n",
    "            pred_ppg.squeeze(-1),\n",
    "            labels.squeeze(-1),\n",
    "            diff_flag=diff_flag,\n",
    "            Fs=FS,\n",
    "            std=3.0)\n",
    "        if torch.isnan(loss_time):\n",
    "            loss_time = 0\n",
    "\n",
    "        loss = 0.2 * loss_time + 1.0 * loss_CE + 1.0 * loss_hr\n",
    "        return loss"
   ],
   "id": "85beb3f5bf15603a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:49:01.145964Z",
     "start_time": "2024-07-19T12:49:01.142414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "class HRHybridLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.2, beta=1.0, gamma=1.0):\n",
    "        super(HRHybridLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, prediction, ground_truth):\n",
    "        # Temporal Loss (negative Pearson correlation)\n",
    "        l_time = -self.pearson_correlation(prediction, ground_truth)\n",
    "        print(f'l_time={l_time}')\n",
    "\n",
    "        # Frequency Loss\n",
    "        l_freq = self.frequency_loss(prediction, ground_truth)\n",
    "        print(f'l_freq={l_freq}')\n",
    "\n",
    "        # HR Distance Loss\n",
    "        l_hr = self.hr_distance_loss(prediction, ground_truth)\n",
    "        print(f'l_hr={l_hr}')\n",
    "\n",
    "        # Combine losses\n",
    "        # total_loss = self.alpha * l_time + self.beta * l_freq + self.gamma * l_hr\n",
    "        total_loss = self.beta * l_freq + self.gamma * l_hr\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def pearson_correlation(self, x, y):\n",
    "        # Compute Pearson correlation\n",
    "        x_mean = torch.mean(x)\n",
    "        y_mean = torch.mean(y)\n",
    "\n",
    "        num = torch.sum((x - x_mean) * (y - y_mean))\n",
    "        den = torch.sqrt(torch.sum((x - x_mean) ** 2) * torch.sum((y - y_mean) ** 2))\n",
    "\n",
    "        return num / den\n",
    "\n",
    "    def frequency_loss(self, pred_bvp, gt_bvp):\n",
    "        # Compute PSD\n",
    "        pred_psd = torch.abs(torch.fft.fft(pred_bvp)) ** 2\n",
    "        gt_psd = torch.abs(torch.fft.fft(gt_bvp)) ** 2\n",
    "\n",
    "        # Find max index of ground truth PSD\n",
    "        gt_max_idx = torch.argmax(gt_psd)\n",
    "\n",
    "        # Compute cross-entropy\n",
    "        return F.cross_entropy(pred_psd.unsqueeze(0), gt_max_idx.unsqueeze(0))\n",
    "\n",
    "    def hr_distance_loss(self, pred_hr, gt_hr):\n",
    "        # Assuming pred_hr and gt_hr are distributions\n",
    "        return F.kl_div(pred_hr, gt_hr, reduction='batchmean')"
   ],
   "id": "42dbd24f8aa76ad1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:49:01.149298Z",
     "start_time": "2024-07-19T12:49:01.146519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "\n",
    "# The timestamp is the unique identifier for this training run\n",
    "zone = timezone('Europe/Berlin')\n",
    "timestamp = datetime.now().astimezone(zone).strftime('%Y%m%d_%H%M%S')\n",
    "manifest['timestamp'] = timestamp\n",
    "\n",
    "epochs = 50\n",
    "manifest['epochs'] = epochs\n",
    "\n",
    "loss_fn = HRHybridLoss()\n",
    "manifest['loss_fn'] = 'HRHybridLoss'\n",
    "\n",
    "learning_rate = 0.000001\n",
    "manifest['learning_rate'] = learning_rate"
   ],
   "id": "a2e8a777bc0c7a3d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:49:04.092458Z",
     "start_time": "2024-07-19T12:49:01.149881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "from respiration.extractor.rhythm_former import RhythmFormer\n",
    "\n",
    "for model_name, model_path in models.items():\n",
    "    model = RhythmFormer()\n",
    "    # Fix model loading: Some key have an extra 'module.' prefix\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    manifest = manifest.copy()\n",
    "    manifest['model'] = model_name\n",
    "    manifest['models'] = []\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    manifest['optimizer'] = 'AdamW'\n",
    "\n",
    "    if model_path is not None:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    model_dir = utils.dir_path(\n",
    "        'models',\n",
    "        'rhythm_former',\n",
    "        timestamp,\n",
    "        model_name,\n",
    "        mkdir=True)\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        training_loader = VitalCamLoader(training, parts=6, device=device)\n",
    "        testing_loader = VitalCamLoader(testing, parts=6, device=device)\n",
    "\n",
    "        train_loss = 0\n",
    "        for (frames, target) in tqdm(training_loader, desc=f'Training'):\n",
    "            frames = preprocess_frames(frames)\n",
    "            target = target.unsqueeze(0)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(frames)\n",
    "            # print(f'output.shape={output.shape}')\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(output, target)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            del frames, target, output, loss\n",
    "\n",
    "        testing_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (frames, target) in tqdm(testing_loader, desc=f'Testing'):\n",
    "                frames = preprocess_frames(frames)\n",
    "                target = target.unsqueeze(0)\n",
    "\n",
    "                output = model(frames)\n",
    "                loss = loss_fn(output, target)\n",
    "                testing_loss += loss.item()\n",
    "\n",
    "                del frames, target, output, loss\n",
    "\n",
    "        # Compute the average loss\n",
    "        train_loss /= len(training)\n",
    "        testing_loss /= len(testing)\n",
    "\n",
    "        if testing_loss < best_loss:\n",
    "            best_loss = testing_loss\n",
    "            model_file = utils.file_path(model_dir, f'{model_name}_{epoch}.pth')\n",
    "\n",
    "            manifest['best_loss'] = best_loss\n",
    "            manifest['models'].append({\n",
    "                'epoch': epoch,\n",
    "                'model_file': model_file,\n",
    "                'train_loss': train_loss,\n",
    "                'test_loss': testing_loss,\n",
    "            })\n",
    "\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "\n",
    "        print(f'{model_name}[{epoch + 1}/{epochs}] '\n",
    "              f'train-loss={train_loss} '\n",
    "              f'test-loss={testing_loss}')\n",
    "\n",
    "    # Save the manifest\n",
    "    manifest_file = utils.file_path(model_dir, 'manifest.json')\n",
    "    utils.write_json(manifest_file, manifest)"
   ],
   "id": "9fedbf0daa0806cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/120 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0610d545a7c44734a65c94ed182d81ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_time=0.26790231466293335\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [1, 600], got [1]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 43\u001B[0m\n\u001B[1;32m     39\u001B[0m output \u001B[38;5;241m=\u001B[39m model(frames)\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# print(f'output.shape={output.shape}')\u001B[39;00m\n\u001B[1;32m     41\u001B[0m \n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# Compute the loss\u001B[39;00m\n\u001B[0;32m---> 43\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# Backward pass\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[10], line 20\u001B[0m, in \u001B[0;36mHRHybridLoss.forward\u001B[0;34m(self, prediction, ground_truth)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml_time=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ml_time\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Frequency Loss\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m l_freq \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrequency_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mground_truth\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml_freq=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ml_freq\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# HR Distance Loss\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[10], line 52\u001B[0m, in \u001B[0;36mHRHybridLoss.frequency_loss\u001B[0;34m(self, pred_bvp, gt_bvp)\u001B[0m\n\u001B[1;32m     49\u001B[0m gt_max_idx \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(gt_psd)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# Compute cross-entropy\u001B[39;00m\n\u001B[0;32m---> 52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred_psd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgt_max_idx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:3086\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3084\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3085\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3086\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected target size [1, 600], got [1]"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "xxx = torch.randn(3600)\n",
    "yyy = torch.randn(3600)\n",
    "\n",
    "# F.kl_div(xxx.log(), yyy)\n",
    "\n",
    "normal_sampling(np.argmax(0.3), 0, 3)\n",
    "# HRHybridLoss()(xxx, yyy)"
   ],
   "id": "4b8c27424fe62caa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
