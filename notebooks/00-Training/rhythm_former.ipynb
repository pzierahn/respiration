{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train Rhythm Former\n",
    "\n",
    "This notebook trains and fine-tunes the Rhythm Former model on the VitalCam dataset."
   ],
   "id": "4c8a3ac7b2973e9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "manifest = {}",
   "id": "b5b5aa78287b1cdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.utils as utils\n",
    "from respiration.dataset import (\n",
    "    VitalCamSet,\n",
    "    VitalCamLoader,\n",
    ")\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "scenarios_all = dataset.get_scenarios(['303_normalized_face'])\n",
    "\n",
    "split_ratio = 0.8\n",
    "manifest['split_ratio'] = split_ratio\n",
    "\n",
    "training = scenarios_all[:int(len(scenarios_all) * split_ratio)]\n",
    "manifest['training_scenarios'] = training\n",
    "\n",
    "testing = scenarios_all[int(len(scenarios_all) * split_ratio):]\n",
    "manifest['testing_scenarios'] = testing\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "manifest['device'] = device"
   ],
   "id": "a986fa7a5e5415b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def preprocess_frames(frames):\n",
    "    # Preprocess the frames to be in 128x128 with torch\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(mode='RGB'),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Transform each frame\n",
    "    transformed_frames = torch.stack([\n",
    "        transform(frame) for frame in frames\n",
    "    ])\n",
    "\n",
    "    return transformed_frames.unsqueeze(0).to(device)"
   ],
   "id": "ad438dcfe2b366f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model_mmpd = utils.file_path('data', 'rhythm_former', 'MMPD_intra_RhythmFormer.pth')\n",
    "model_pure = utils.file_path('data', 'rhythm_former', 'PURE_cross_RhythmFormer.pth')\n",
    "model_ubfc = utils.file_path('data', 'rhythm_former', 'UBFC_cross_RhythmFormer.pth')\n",
    "\n",
    "models = {\n",
    "    'RhythmFormer': None,\n",
    "    # 'RhythmFormer_MMPD': model_mmpd,\n",
    "    # 'RhythmFormer_PURE': model_pure,\n",
    "    # 'RhythmFormer_UBFC': model_ubfc,\n",
    "}\n",
    "manifest['models'] = models"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def normal_sampling(mean: torch.Tensor, std: torch.Tensor, label_k: torch.Tensor):\n",
    "    return torch.exp(-((label_k - mean) ** 2) / (2 * std ** 2)) / (torch.sqrt(torch.tensor(2 * torch.pi)) * std)\n",
    "\n",
    "\n",
    "def filtered_periodogram(\n",
    "        time_series: torch.Tensor,\n",
    "        sampling_rate: int,\n",
    "        min_freq: float = 0,\n",
    "        max_freq: float = float('inf')) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Computes the power spectral density (PSD) of a signal within a given frequency range.\n",
    "    :param time_series: Respiratory signal\n",
    "    :param sampling_rate: Sampling rate\n",
    "    :param min_freq: minimum frequency\n",
    "    :param max_freq: maximum frequency\n",
    "    :return: Frequencies and FFT result\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the power spectral density (PSD) using periodogram\n",
    "    psd = (torch.fft.fft(time_series).abs() ** 2) / time_series.shape[0]\n",
    "\n",
    "    psd = psd[:len(psd) // 2]\n",
    "    freq = torch.fft.fftfreq(time_series.shape[0], 1 / sampling_rate)[:len(psd)]\n",
    "\n",
    "    # Find the indices corresponding to the frequency range\n",
    "    idx = (freq >= min_freq) & (freq <= max_freq)\n",
    "\n",
    "    # Extract the frequencies and PSDs within the specified range\n",
    "    freq_range = freq[idx]\n",
    "    psd_range = psd[idx]\n",
    "\n",
    "    # Make the psd sum to 1\n",
    "    psd_range = psd_range / psd_range.sum()\n",
    "\n",
    "    return freq_range, psd_range\n",
    "\n",
    "\n",
    "def euclidean_distance(pred_psd: torch.Tensor, gt_psd: torch.Tensor):\n",
    "    return torch.dist(pred_psd.softmax(dim=0), gt_psd.softmax(dim=0))\n",
    "\n",
    "\n",
    "def cosine_distance(pred_psd: torch.Tensor, gt_psd: torch.Tensor):\n",
    "    return 1 - F.cosine_similarity(pred_psd, gt_psd, dim=0)\n",
    "\n",
    "\n",
    "def frequency_loss(pred_psd: torch.Tensor, gt_psd: torch.Tensor):\n",
    "    return F.cross_entropy(pred_psd, torch.argmax(gt_psd))\n",
    "    # return F.cross_entropy(pred_psd.softmax(dim=0), gt_psd)\n",
    "\n",
    "\n",
    "def pearson_correlation(prediction: torch.Tensor, ground_truth: torch.Tensor):\n",
    "    \"\"\"Compute Pearson correlation coefficient\"\"\"\n",
    "    x_mean = torch.mean(prediction)\n",
    "    y_mean = torch.mean(ground_truth)\n",
    "\n",
    "    num = torch.sum((prediction - x_mean) * (ground_truth - y_mean))\n",
    "    den = torch.sqrt(torch.sum((prediction - x_mean) ** 2) * torch.sum((ground_truth - y_mean) ** 2))\n",
    "\n",
    "    correlation = num / den\n",
    "\n",
    "    # Bigger correlation means smaller loss, so we negate it\n",
    "    return 1 - correlation\n",
    "\n",
    "\n",
    "def norm_loss(pred_psd: torch.Tensor, gt_psd: torch.Tensor) -> torch.Tensor:\n",
    "    std = torch.tensor(3.0)\n",
    "\n",
    "    pred_mean = torch.argmax(pred_psd)\n",
    "    pred_label = torch.arange(pred_psd.shape[0], device=pred_psd.device)\n",
    "    pred_norm = normal_sampling(pred_mean, std, pred_label)\n",
    "\n",
    "    gt_mean = torch.argmax(gt_psd)\n",
    "    gt_label = torch.arange(gt_psd.shape[0], device=gt_psd.device)\n",
    "    gt_norm = normal_sampling(gt_mean, std, gt_label)\n",
    "\n",
    "    criterion = torch.nn.KLDivLoss(reduction='none')\n",
    "    return criterion(pred_norm.log(), gt_norm).sum()\n",
    "\n",
    "\n",
    "class HRHybridLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HRHybridLoss, self).__init__()\n",
    "\n",
    "    def forward(self, prediction, ground_truth):\n",
    "        # Temporal Loss (negative Pearson correlation)\n",
    "        pearson = pearson_correlation(prediction, ground_truth)\n",
    "\n",
    "        freq_pred, pred_psd = filtered_periodogram(prediction, 30, 0.08, 0.6)\n",
    "        freq_gt, gt_psd = filtered_periodogram(ground_truth, 30, 0.08, 0.6)\n",
    "\n",
    "        freq_loss = frequency_loss(pred_psd, gt_psd)\n",
    "        # cosine = cosine_distance(pred_psd, gt_psd)\n",
    "        # euclid = euclidean_distance(pred_psd, gt_psd)\n",
    "\n",
    "        pred_freq = freq_pred[torch.argmax(pred_psd)]\n",
    "        gt_freq = freq_gt[torch.argmax(gt_psd)]\n",
    "\n",
    "        freq_distance = (pred_freq - gt_freq).abs() / (0.6 - 0.08)\n",
    "        # freq_distance = (pred_freq - gt_freq).abs()\n",
    "\n",
    "        # KL Divergence\n",
    "        # psd_prediction = torch.fft.fft(prediction).abs() ** 2\n",
    "        # psd_ground_truth = torch.fft.fft(ground_truth).abs() ** 2\n",
    "        # kl_div = torch.nn.functional.kl_div(\n",
    "        #     pred_psd.softmax(dim=0),\n",
    "        #     gt_psd,\n",
    "        #     reduction='batchmean',\n",
    "        # )\n",
    "        norm_l = norm_loss(pred_psd, gt_psd)\n",
    "\n",
    "        # Combine losses\n",
    "        # total_loss = 0.2 * pearson + 0.4 * freq_loss + 0.4 * cosine\n",
    "        # total_loss = 0.3 * pearson + 0.7 * freq_distance\n",
    "        # total_loss = 0.2 * pearson + 0.1 * freq_distance + 0.4 * freq_loss + 0.3 * cosine\n",
    "        total_loss = 0.2 * pearson + 1.0 * freq_loss + 1.0 * norm_l\n",
    "        # total_loss = 0.2 * pearson + 1.0 * freq_distance + 1.0 * norm_l\n",
    "\n",
    "        print(\n",
    "            f'pearson={pearson:.3f} '\n",
    "            # f'euclid={euclid:.3f} '\n",
    "            f'norm_l={norm_l:.3f} '\n",
    "            f'freq_loss={freq_loss:.3f} '\n",
    "            # f'cosine={cosine:.3f} '\n",
    "            # f'freq_distance={freq_distance:.2f} '\n",
    "            f'total_loss={total_loss.item():2.3f} '\n",
    "            f'pred_freq={pred_freq.item():.2f} '\n",
    "            f'gt_freq={gt_freq.item():.2f}')\n",
    "\n",
    "        return total_loss"
   ],
   "id": "42dbd24f8aa76ad1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "\n",
    "# The timestamp is the unique identifier for this training run\n",
    "zone = timezone('Europe/Berlin')\n",
    "timestamp = datetime.now().astimezone(zone).strftime('%Y%m%d_%H%M%S')\n",
    "manifest['timestamp'] = timestamp\n",
    "\n",
    "epochs = 22\n",
    "manifest['epochs'] = epochs\n",
    "\n",
    "loss_fn = HRHybridLoss()\n",
    "manifest['loss_fn'] = 'HRHybridLoss'\n",
    "\n",
    "# learning_rate = 0.00001\n",
    "learning_rate = 9e-3\n",
    "manifest['learning_rate'] = learning_rate"
   ],
   "id": "a2e8a777bc0c7a3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "from respiration.extractor.rhythm_former import RhythmFormer\n",
    "\n",
    "for model_name, model_path in models.items():\n",
    "    model = RhythmFormer()\n",
    "    # Fix model loading: Some key have an extra 'module.' prefix\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    manifest = manifest.copy()\n",
    "    manifest['model'] = model_name\n",
    "    manifest['models'] = []\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    manifest['optimizer'] = 'Adam'\n",
    "\n",
    "    if model_path is not None:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    model_dir = utils.dir_path(\n",
    "        'models',\n",
    "        'rhythm_former',\n",
    "        timestamp,\n",
    "        model_name,\n",
    "        mkdir=True)\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        training_loader = VitalCamLoader(training, parts=6, device=device)\n",
    "        testing_loader = VitalCamLoader(testing, parts=6, device=device)\n",
    "\n",
    "        train_loss = 0\n",
    "        for (frames, target) in tqdm(training_loader, desc=f'Training'):\n",
    "            frames = preprocess_frames(frames)\n",
    "            # target = target.unsqueeze(0)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(frames).squeeze(0)\n",
    "            # print(f'output.shape={output.shape} target.shape={target.shape}')\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(output, target)\n",
    "            # print(f'loss={loss.item()}')\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            del frames, target, output, loss\n",
    "\n",
    "        testing_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (frames, target) in tqdm(testing_loader, desc=f'Testing'):\n",
    "                frames = preprocess_frames(frames)\n",
    "                # target = target.unsqueeze(0)\n",
    "\n",
    "                output = model(frames).squeeze(0)\n",
    "                loss = loss_fn(output, target)\n",
    "                # print(f'loss={loss.item()}')\n",
    "                testing_loss += loss.item()\n",
    "\n",
    "                del frames, target, output, loss\n",
    "\n",
    "        # Compute the average loss\n",
    "        train_loss /= len(training_loader)\n",
    "        testing_loss /= len(testing_loader)\n",
    "\n",
    "        if testing_loss < best_loss:\n",
    "            best_loss = testing_loss\n",
    "            model_file = utils.file_path(model_dir, f'{model_name}_{epoch}.pth')\n",
    "\n",
    "            manifest['best_loss'] = best_loss\n",
    "            manifest['models'].append({\n",
    "                'epoch': epoch,\n",
    "                'model_file': model_file,\n",
    "                'train_loss': train_loss,\n",
    "                'test_loss': testing_loss,\n",
    "            })\n",
    "\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "\n",
    "        print(f'{model_name}[{epoch + 1}/{epochs}] '\n",
    "              f'train-loss={train_loss:.3f} '\n",
    "              f'test-loss={testing_loss:.3f}')\n",
    "\n",
    "        # Save the manifest\n",
    "        manifest['epoch'] = epoch\n",
    "        manifest_file = utils.file_path(model_dir, 'manifest.json')\n",
    "        utils.write_json(manifest_file, manifest)"
   ],
   "id": "9fedbf0daa0806cb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
