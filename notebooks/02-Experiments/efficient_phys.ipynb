{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuned\n",
    "\n",
    "This notebook extracts respiration signals for each subject using the fine-tuned models."
   ],
   "id": "156541bc5c985cd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "\n",
    "import respiration.utils as utils\n",
    "\n",
    "# Map model names to their paths\n",
    "models = {\n",
    "    'BP4D_PseudoLabel_EfficientPhys': utils.file_path('data', 'rPPG-Toolbox', 'BP4D_PseudoLabel_EfficientPhys.pth'),\n",
    "    'MA-UBFC_efficientphys': utils.file_path('data', 'rPPG-Toolbox', 'MA-UBFC_efficientphys.pth'),\n",
    "    'PURE_EfficientPhys': utils.file_path('data', 'rPPG-Toolbox', 'PURE_EfficientPhys.pth'),\n",
    "    'SCAMPS_EfficientPhys': utils.file_path('data', 'rPPG-Toolbox', 'SCAMPS_EfficientPhys.pth'),\n",
    "    'UBFC-rPPG_EfficientPhys': utils.file_path('data', 'rPPG-Toolbox', 'UBFC-rPPG_EfficientPhys.pth'),\n",
    "}\n",
    "\n",
    "manifests = []\n",
    "\n",
    "signals_dir = utils.dir_path('outputs', 'signals', mkdir=True)\n",
    "\n",
    "# Store the manifests\n",
    "manifests_path = utils.join_paths(signals_dir, 'efficient_phys_manifest.json')\n",
    "utils.write_json(manifests_path, manifests)\n",
    "\n",
    "utils.pretty_print(models)"
   ],
   "id": "41913a5f51b91d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "scenarios = dataset.get_scenarios(['101_natural_lighting'])\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "dim = 72\n",
    "frame_depth = 20"
   ],
   "id": "3eabcd4e01b673c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from respiration.extractor.efficient_phys import EfficientPhys\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for (subject, setting) in tqdm(scenarios):\n",
    "    print(f\"Processing {subject} - {setting}\")\n",
    "\n",
    "    video_path = dataset.get_video_path(subject, setting)\n",
    "    frame_count = utils.get_frame_count(video_path)\n",
    "    chunk_size = (frame_count // frame_depth) * frame_depth - (frame_depth - 1)\n",
    "    # chunk_size = frame_depth * 20 + 1\n",
    "\n",
    "    frames, meta = utils.read_video_rgb(video_path, chunk_size)\n",
    "    frames = utils.down_sample_video(frames, dim)\n",
    "    frames = torch.tensor(frames, dtype=torch.float32, device=device).permute(0, 3, 1, 2)\n",
    "\n",
    "    for (model_id, model_path) in models.items():\n",
    "        print(f\"--> Using {model_id} model\")\n",
    "        # Wrap modul in nn.DataParallel to fix the model loading issue\n",
    "        model = torch.nn.DataParallel(EfficientPhys(img_size=dim, frame_depth=frame_depth))\n",
    "        model.to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        start = dt.datetime.now()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = model(frames).cpu().detach().numpy().squeeze()\n",
    "\n",
    "        predictions.append({\n",
    "            'model': model_id,\n",
    "            'subject': subject,\n",
    "            'setting': setting,\n",
    "            'duration': dt.datetime.now() - start,\n",
    "            'chunk_size': chunk_size,\n",
    "            'sampling_rate': meta.fps,\n",
    "            'signal': prediction.tolist(),\n",
    "        })\n",
    "\n",
    "    del frames\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "# Store the predictions to csv\n",
    "signals_path = utils.join_paths(signals_dir, 'efficient_phys_predictions.csv')\n",
    "\n",
    "# Append the predictions to the csv file\n",
    "if os.path.exists(signals_path):\n",
    "    predictions.to_csv(signals_path, mode='a', header=False, index=False)\n",
    "else:\n",
    "    predictions.to_csv(signals_path, index=False)"
   ],
   "id": "44cbf5bc27ff119a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions.head()",
   "id": "ab2b7b98a1d93f49",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
