{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extract respiratory signals with RAFT\n",
    "\n",
    "Recurrent All-Pairs Field Transforms (RAFT) is a deep learning model for optical flow estimation. The optical flow directions and magnitudes can be used to extract respiratory signals from videos. This notebook demonstrates how to use RAFT to extract respiratory signals from videos."
   ],
   "id": "e931c39f16bae87e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "\n",
    "# The scenarios (subject, setting) to process\n",
    "scenarios = dataset.get_scenarios(['101_natural_lighting'])\n",
    "\n",
    "# The RAFT models to use for optical flow estimation\n",
    "raft_models = [\n",
    "    'raft_large',\n",
    "    'raft_small',\n",
    "]"
   ],
   "id": "3f5527a9bf000",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.utils as utils\n",
    "\n",
    "output_dir = utils.dir_path('outputs', 'signals', mkdir=True)\n",
    "flows_dir = utils.dir_path('outputs', 'raft_flows', mkdir=True)\n",
    "manifest_file = utils.join_paths(output_dir, 'raft_manifest.json')"
   ],
   "id": "ff44cce386692d39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 1: Extract optical flows\n",
    "\n",
    "This part is heavy on computational resources and may take a long time to complete. The optical flows are extracted from the videos and saved to disk. The extracted optical flows are stored in the `outputs/raft_flows` directory."
   ],
   "id": "68dfab9c5a7fbad7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "import respiration.utils as utils\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "\n",
    "manifest = {\n",
    "    'timestamp_start': datetime.now(),\n",
    "    'scenarios': scenarios,\n",
    "    'device': device,\n",
    "    'raft_models': raft_models,\n",
    "    'flows': [],\n",
    "    'incomplete_rois': [],\n",
    "}"
   ],
   "id": "eb2f55e2aeddbde6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import respiration.extractor.raft as raft\n",
    "\n",
    "# Number of frames that are processed at once\n",
    "batch_size = 20\n",
    "\n",
    "for (subject, setting) in tqdm(scenarios):\n",
    "    print(f'Processing {subject} - {setting}')\n",
    "\n",
    "    video_path = dataset.get_video_path(subject, setting)\n",
    "    param = utils.get_video_params(video_path)\n",
    "\n",
    "    batches = math.ceil(param.num_frames / (batch_size // 2))\n",
    "\n",
    "    for raft_model in raft_models:\n",
    "        model = raft.load_model(raft_model, device)\n",
    "\n",
    "        # Store the optical flows vectors (N, 2, H, W). N is the number of frames \n",
    "        # in the video minus one, because we calculate the optical flow between consecutive frames.\n",
    "        optical_flows = np.zeros((param.num_frames - 1, 2, param.height, param.width), dtype=np.float32)\n",
    "\n",
    "        # Extract the optical flow from the video in batches\n",
    "        for batch in range(0, batches):\n",
    "            # Calculate the start frame for this batch\n",
    "            start = (batch_size // 2) * batch\n",
    "\n",
    "            # Calculate the number of frames to process in this batch\n",
    "            num_frames = min(start + batch_size, param.num_frames) - start\n",
    "\n",
    "            chunk, _ = utils.read_video_rgb(video_path, num_frames, start)\n",
    "            chunk = raft.preprocess(chunk, device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                flows = model(chunk[:-1], chunk[1:])\n",
    "\n",
    "            # Only keep the last flow iteration\n",
    "            flows = flows[-1]\n",
    "\n",
    "            for idx in range(flows.shape[0]):\n",
    "                # Add the optical flow to the numpy array\n",
    "                optical_flows[start + idx] = flows[idx].cpu().numpy()\n",
    "\n",
    "            # Garbage collect...\n",
    "            del chunk\n",
    "            del flows\n",
    "\n",
    "        # Store the extracted signals\n",
    "        filename = f'{subject}_{setting}_{raft_model}.npy'\n",
    "        flow_file = os.path.join(flows_dir, filename)\n",
    "        np.save(flow_file, optical_flows)\n",
    "\n",
    "        # Garbage collect the optical flows (8.2GB)\n",
    "        del optical_flows\n",
    "\n",
    "        manifest['flows'].append({\n",
    "            'subject': subject,\n",
    "            'setting': setting,\n",
    "            'model': raft_model,\n",
    "            'filename': filename,\n",
    "        })"
   ],
   "id": "c54b105646357fb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "manifest['timestamp_finish'] = datetime.now()\n",
    "utils.write_json(manifest_file, manifest)"
   ],
   "id": "4ade1837050c82f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 2: Export respiratory signals\n",
    "\n",
    "This part reads the extracted optical flows and calculates the respiratory signals. The respiratory signals are saved to a CSV file in the `outputs/signals` directory."
   ],
   "id": "71b4a5c313f5d9c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Read the manifest file\n",
    "manifest = utils.read_json(manifest_file)"
   ],
   "id": "4346256ca89d898a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import respiration.roi as roi\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "extracted_signals = []\n",
    "\n",
    "for (subject, setting) in tqdm(scenarios):\n",
    "    for raft_model in raft_models:\n",
    "        filename = f'{subject}_{setting}_{raft_model}.npy'\n",
    "        flow_file = os.path.join(flows_dir, filename)\n",
    "        assert os.path.exists(flow_file), f'File not found: {flow_file}'\n",
    "\n",
    "        optical_flows = np.load(flow_file)\n",
    "\n",
    "        video_path = dataset.get_video_path(subject, setting)\n",
    "        params = utils.get_video_params(video_path)\n",
    "        first_frame = dataset.get_first_frame(subject, setting)\n",
    "        roi_areas = roi.get_roi_areas(first_frame)\n",
    "        if len(roi_areas) < 3:\n",
    "            print(f'Warning: only {len(roi_areas)} ROIs found for {subject} - {setting}')\n",
    "            manifest['incomplete_rois'].append({\n",
    "                'subject': subject,\n",
    "                'setting': setting,\n",
    "                'rois': [name for (_, name) in roi_areas],\n",
    "            })\n",
    "\n",
    "        for ((x, y, w, h), name) in roi_areas:\n",
    "            # Select the motion vectors in the region of interest (N, 2, H, W)\n",
    "            flow_region = optical_flows[:, :, y:y + h, x:x + w]\n",
    "\n",
    "            # Horizontal motion (N, H, W)\n",
    "            u = flow_region[:, 0, :, :]\n",
    "\n",
    "            # Vertical motion (N, H, W)\n",
    "            v = flow_region[:, 1, :, :]\n",
    "\n",
    "            # Calculate the magnitudes of the motion vectors (N, H, W)\n",
    "            magnitudes = np.sqrt(u ** 2 + v ** 2)\n",
    "\n",
    "            # Calculate the mean and standard deviation of the magnitudes\n",
    "            uv_mean_curve = np.mean(magnitudes, axis=(1, 2))\n",
    "            uv_std_curve = np.std(magnitudes, axis=(1, 2))\n",
    "\n",
    "            # Calculate the mean and standard deviation of the vertical motion\n",
    "            v_mean_curve = v.mean(axis=(1, 2))\n",
    "            v_std_curve = v.std(axis=(1, 2))\n",
    "\n",
    "            # Store the extracted signals\n",
    "            extracted_signals.append({\n",
    "                'subject': subject,\n",
    "                'setting': setting,\n",
    "                'model': raft_model,\n",
    "                'roi': name,\n",
    "                'sampling_rate': params.fps,\n",
    "                'signal_uv': uv_mean_curve.tolist(),\n",
    "                'signal_uv_std': uv_std_curve.tolist(),\n",
    "                'signal_v': v_mean_curve.tolist(),\n",
    "                'signal_v_std': v_std_curve.tolist(),\n",
    "            })\n",
    "\n",
    "        del optical_flows"
   ],
   "id": "ed2b36e28722b16e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "signals_df = pd.DataFrame(extracted_signals)\n",
    "predictions_file = os.path.join(output_dir, 'raft_predictions.csv')\n",
    "signals_df.to_csv(predictions_file, index=False)"
   ],
   "id": "9b4b207e7fe79198",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "signals_df.head()",
   "id": "fa3b70a86faefa49",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
