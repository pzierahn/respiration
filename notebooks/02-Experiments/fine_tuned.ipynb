{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuned\n",
    "\n",
    "This notebook extracts respiration signals for each subject using the fine-tuned models."
   ],
   "id": "156541bc5c985cd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.utils as utils\n",
    "\n",
    "# Fine tuned model ids\n",
    "tuned_models = {\n",
    "    '20240509_122327',\n",
    "    '20240509_124125',\n",
    "    '20240509_132544',\n",
    "    '20240509_135603',\n",
    "    '20240509_144815',\n",
    "    '20240509_151734',\n",
    "}\n",
    "\n",
    "# Map model names to their paths\n",
    "models = {\n",
    "    'efficient_phys': utils.file_path('data', 'rPPG-Toolbox', 'BP4D_PseudoLabel_EfficientPhys.pth'),\n",
    "}\n",
    "\n",
    "manifests = []\n",
    "\n",
    "# Add the best fine-tuned model weights to the model paths\n",
    "for model_id in tuned_models:\n",
    "    model_dir = utils.dir_path('models', 'fine_tuned', model_id)\n",
    "\n",
    "    manifest_path = utils.dir_path(model_dir, 'manifest.json')\n",
    "    manifest = utils.read_json(manifest_path)\n",
    "    best_model = manifest['tuned_models'][-1]\n",
    "\n",
    "    model_path = utils.join_paths(model_dir, best_model['model'])\n",
    "    models[model_id] = model_path\n",
    "    manifests.append(manifest)\n",
    "\n",
    "utils.pretty_print(models)"
   ],
   "id": "41913a5f51b91d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "scenarios = dataset.get_scenarios(['101_natural_lighting'])\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "dim = 72\n",
    "frame_depth = 20"
   ],
   "id": "3eabcd4e01b673c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from respiration.extractor.efficient_phys import EfficientPhys\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for (subject, setting) in tqdm(scenarios):\n",
    "    print(f\"Processing {subject} - {setting}\")\n",
    "\n",
    "    video_path = dataset.get_video_path(subject, setting)\n",
    "    frame_count = utils.get_frame_count(video_path)\n",
    "    chunk_size = (frame_count // frame_depth) * frame_depth - (frame_depth - 1)\n",
    "    # chunk_size = frame_depth * 20 + 1\n",
    "\n",
    "    frames, meta = utils.read_video_rgb(video_path, chunk_size)\n",
    "    frames = utils.down_sample_video(frames, dim)\n",
    "    frames = torch.tensor(frames, dtype=torch.float32, device=device).permute(0, 3, 1, 2)\n",
    "\n",
    "    for (model_id, model_path) in models.items():\n",
    "        print(f\"--> Using {model_id} model\")\n",
    "        # Wrap modul in nn.DataParallel to fix the model loading issue\n",
    "        model = torch.nn.DataParallel(EfficientPhys(img_size=dim, frame_depth=frame_depth))\n",
    "        model.to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        start = dt.datetime.now()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = model(frames).cpu().detach().numpy().squeeze()\n",
    "\n",
    "        predictions.append({\n",
    "            'model': model_id,\n",
    "            'subject': subject,\n",
    "            'setting': setting,\n",
    "            'duration': dt.datetime.now() - start,\n",
    "            'chunk_size': chunk_size,\n",
    "            'sampling_rate': meta.fps,\n",
    "            'signal': prediction.tolist(),\n",
    "        })\n",
    "\n",
    "    del frames\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "# Store the predictions to csv\n",
    "signals_dir = utils.dir_path('outputs', 'signals', mkdir=True)\n",
    "signals_path = utils.join_paths(signals_dir, 'fine_tuned_predictions.csv')\n",
    "predictions.to_csv(signals_path, index=False)\n",
    "\n",
    "# Store the manifests\n",
    "manifests_path = utils.join_paths(signals_dir, 'fine_tuned_manifest.json')"
   ],
   "id": "44cbf5bc27ff119a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions.head()",
   "id": "ab2b7b98a1d93f49",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
