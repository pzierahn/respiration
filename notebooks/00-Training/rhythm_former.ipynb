{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train Rhythm Former\n",
    "\n",
    "This notebook trains and fine-tunes the Rhythm Former model on the VitalCam dataset."
   ],
   "id": "4c8a3ac7b2973e9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "manifest = {}",
   "id": "b5b5aa78287b1cdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.utils as utils\n",
    "from respiration.dataset import (\n",
    "    VitalCamSet,\n",
    "    VitalCamLoader,\n",
    ")\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "scenarios_all = dataset.get_scenarios(['303_normalized_face'])\n",
    "\n",
    "split_ratio = 0.8\n",
    "manifest['split_ratio'] = split_ratio\n",
    "\n",
    "training = scenarios_all[:int(len(scenarios_all) * split_ratio)]\n",
    "manifest['training_scenarios'] = training\n",
    "\n",
    "testing = scenarios_all[int(len(scenarios_all) * split_ratio):]\n",
    "manifest['testing_scenarios'] = testing\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "manifest['device'] = device"
   ],
   "id": "a986fa7a5e5415b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def preprocess_frames(frames):\n",
    "    # Preprocess the frames to be in 128x128 with torch\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(mode='RGB'),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Transform each frame\n",
    "    transformed_frames = torch.stack([\n",
    "        transform(frame) for frame in frames\n",
    "    ])\n",
    "\n",
    "    return transformed_frames.unsqueeze(0).to(device)"
   ],
   "id": "ad438dcfe2b366f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model_mmpd = utils.file_path('data', 'rhythm_former', 'MMPD_intra_RhythmFormer.pth')\n",
    "model_pure = utils.file_path('data', 'rhythm_former', 'PURE_cross_RhythmFormer.pth')\n",
    "model_ubfc = utils.file_path('data', 'rhythm_former', 'UBFC_cross_RhythmFormer.pth')\n",
    "\n",
    "models = {\n",
    "    'RhythmFormer': None,\n",
    "    # 'RhythmFormer_MMPD': model_mmpd,\n",
    "    # 'RhythmFormer_PURE': model_pure,\n",
    "    # 'RhythmFormer_UBFC': model_ubfc,\n",
    "}\n",
    "manifest['models'] = models"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import scipy\n",
    "from scipy.signal import butter, welch\n",
    "from scipy.sparse import spdiags\n",
    "\n",
    "\n",
    "def get_hr(y, sr=30, min=45, max=150):\n",
    "    p, q = welch(y, sr, nfft=1e5 / sr, nperseg=np.min((len(y) - 1, 256)))\n",
    "    return p[(p > min / 60) & (p < max / 60)][np.argmax(q[(p > min / 60) & (p < max / 60)])] * 60\n",
    "\n",
    "\n",
    "def get_psd(y, sr=30, min=45, max=150):\n",
    "    p, q = welch(y, sr, nfft=1e5 / sr, nperseg=np.min((len(y) - 1, 256)))\n",
    "    return q[(p > min / 60) & (p < max / 60)]\n",
    "\n",
    "\n",
    "def normal_sampling(mean, label_k, std):\n",
    "    return math.exp(-(label_k - mean) ** 2 / (2 * std ** 2)) / (math.sqrt(2 * math.pi) * std)\n",
    "\n",
    "\n",
    "def kl_loss(inputs, labels):\n",
    "    criterion = nn.KLDivLoss(reduction='none')\n",
    "    outputs = torch.log(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    #loss = loss.sum()/loss.shape[0]\n",
    "    loss = loss.sum()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def _detrend(input_signal, lambda_value):\n",
    "    \"\"\"Detrend PPG signal.\"\"\"\n",
    "    signal_length = input_signal.shape[0]\n",
    "    # observation matrix\n",
    "    H = np.identity(signal_length)\n",
    "    ones = np.ones(signal_length)\n",
    "    minus_twos = -2 * np.ones(signal_length)\n",
    "    diags_data = np.array([ones, minus_twos, ones])\n",
    "    diags_index = np.array([0, 1, 2])\n",
    "    D = spdiags(diags_data, diags_index,\n",
    "                (signal_length - 2), signal_length).toarray()\n",
    "    detrended_signal = np.dot(\n",
    "        (H - np.linalg.inv(H + (lambda_value ** 2) * np.dot(D.T, D))), input_signal)\n",
    "    return detrended_signal\n",
    "\n",
    "\n",
    "def calculate_hr(predictions, labels, fs=30, diff_flag=False):\n",
    "    \"\"\"Calculate video-level HR and SNR\"\"\"\n",
    "    if diff_flag:  # if the predictions and labels are 1st derivative of PPG signal.\n",
    "        predictions = _detrend(np.cumsum(predictions), 100)\n",
    "        labels = _detrend(np.cumsum(labels), 100)\n",
    "    else:\n",
    "        predictions = _detrend(predictions, 100)\n",
    "        labels = _detrend(labels, 100)\n",
    "\n",
    "    [b, a] = butter(1, [0.75 / fs * 2, 2.5 / fs * 2], btype='bandpass')\n",
    "    predictions = scipy.signal.filtfilt(b, a, np.double(predictions))\n",
    "    labels = scipy.signal.filtfilt(b, a, np.double(labels))\n",
    "\n",
    "    hr_pred = get_hr(predictions, sr=fs)\n",
    "    hr_label = get_hr(labels, sr=fs)\n",
    "    return hr_pred, hr_label\n",
    "\n",
    "\n",
    "def calculate_psd(predictions, labels, fs=30, diff_flag=False):\n",
    "    \"\"\"Calculate video-level HR and SNR\"\"\"\n",
    "    if diff_flag:  # if the predictions and labels are 1st derivative of PPG signal.\n",
    "        predictions = _detrend(np.cumsum(predictions), 100)\n",
    "        labels = _detrend(np.cumsum(labels), 100)\n",
    "    else:\n",
    "        predictions = _detrend(predictions, 100)\n",
    "        labels = _detrend(labels, 100)\n",
    "    # [b, a] = butter(1, [0.75 / fs * 2, 2.5 / fs * 2], btype='bandpass')\n",
    "    [b, a] = butter(3, [0.08 / fs * 2, 0.6 / fs * 2], btype='bandpass')\n",
    "    predictions = scipy.signal.filtfilt(b, a, np.double(predictions))\n",
    "    labels = scipy.signal.filtfilt(b, a, np.double(labels))\n",
    "    psd_pred = get_psd(predictions, sr=fs)\n",
    "    psd_label = get_psd(labels, sr=fs)\n",
    "    return psd_pred, psd_label\n",
    "\n",
    "\n",
    "class TorchLossComputer(object):\n",
    "    @staticmethod\n",
    "    def compute_complex_absolute_given_k(output, k, N):\n",
    "        two_pi_n_over_N = Variable(2 * math.pi * torch.arange(0, N, dtype=torch.float), requires_grad=True) / N\n",
    "        hanning = Variable(torch.from_numpy(np.hanning(N)).type(torch.FloatTensor), requires_grad=True).view(1, -1)\n",
    "\n",
    "        k = k.type(torch.FloatTensor).cuda()\n",
    "        two_pi_n_over_N = two_pi_n_over_N.cuda()\n",
    "        hanning = hanning.cuda()\n",
    "\n",
    "        output = output.view(1, -1) * hanning\n",
    "        output = output.view(1, 1, -1).type(torch.cuda.FloatTensor)\n",
    "        k = k.view(1, -1, 1)\n",
    "        two_pi_n_over_N = two_pi_n_over_N.view(1, 1, -1)\n",
    "        complex_absolute = torch.sum(output * torch.sin(k * two_pi_n_over_N), dim=-1) ** 2 \\\n",
    "                           + torch.sum(output * torch.cos(k * two_pi_n_over_N), dim=-1) ** 2\n",
    "\n",
    "        return complex_absolute\n",
    "\n",
    "    @staticmethod\n",
    "    def complex_absolute(output, Fs, bpm_range=None):\n",
    "        output = output.view(1, -1)\n",
    "\n",
    "        N = output.size()[1]\n",
    "\n",
    "        unit_per_hz = Fs / N\n",
    "        feasible_bpm = bpm_range / 60.0\n",
    "        k = feasible_bpm / unit_per_hz\n",
    "\n",
    "        # only calculate feasible PSD range [0.7,4]Hz\n",
    "        complex_absolute = TorchLossComputer.compute_complex_absolute_given_k(output, k, N)\n",
    "\n",
    "        return (1.0 / complex_absolute.sum()) * complex_absolute  # Analogous Softmax operator\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_power_spectrum_loss(inputs, target, Fs):\n",
    "        inputs = inputs.view(1, -1)\n",
    "        target = target.view(1, -1)\n",
    "        bpm_range = torch.arange(40, 180, dtype=torch.float).cuda()\n",
    "        #bpm_range = torch.arange(40, 260, dtype=torch.float).cuda()\n",
    "\n",
    "        complex_absolute = TorchLossComputer.complex_absolute(inputs, Fs, bpm_range)\n",
    "\n",
    "        whole_max_val, whole_max_idx = complex_absolute.view(-1).max(0)\n",
    "        whole_max_idx = whole_max_idx.type(torch.float)\n",
    "\n",
    "        #pdb.set_trace()\n",
    "\n",
    "        #return F.cross_entropy(complex_absolute, target.view((1)).type(torch.long)).view(1),  (target.item() - whole_max_idx.item()) ** 2\n",
    "        return F.cross_entropy(complex_absolute, target.view((1)).type(torch.long)), torch.abs(\n",
    "            target[0] - whole_max_idx)\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_power_spectrum_focal_loss(inputs, target, Fs, gamma):\n",
    "        inputs = inputs.view(1, -1)\n",
    "        target = target.view(1, -1)\n",
    "        bpm_range = torch.arange(40, 180, dtype=torch.float).cuda()\n",
    "        #bpm_range = torch.arange(40, 260, dtype=torch.float).cuda()\n",
    "\n",
    "        complex_absolute = TorchLossComputer.complex_absolute(inputs, Fs, bpm_range)\n",
    "\n",
    "        whole_max_val, whole_max_idx = complex_absolute.view(-1).max(0)\n",
    "        whole_max_idx = whole_max_idx.type(torch.float)\n",
    "\n",
    "        #pdb.set_trace()\n",
    "        criterion = FocalLoss(gamma=gamma)\n",
    "\n",
    "        #return F.cross_entropy(complex_absolute, target.view((1)).type(torch.long)).view(1),  (target.item() - whole_max_idx.item()) ** 2\n",
    "        return criterion(complex_absolute, target.view((1)).type(torch.long)), torch.abs(target[0] - whole_max_idx)\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_power_spectrum_forward_pred(inputs, Fs):\n",
    "        inputs = inputs.view(1, -1)\n",
    "        bpm_range = torch.arange(40, 190, dtype=torch.float).cuda()\n",
    "        #bpm_range = torch.arange(40, 180, dtype=torch.float).cuda()\n",
    "        #bpm_range = torch.arange(40, 260, dtype=torch.float).cuda()\n",
    "\n",
    "        complex_absolute = TorchLossComputer.complex_absolute(inputs, Fs, bpm_range)\n",
    "\n",
    "        whole_max_val, whole_max_idx = complex_absolute.view(-1).max(0)\n",
    "        whole_max_idx = whole_max_idx.type(torch.float)\n",
    "\n",
    "        return whole_max_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def Frequency_loss(inputs, _, diff_flag, Fs, std):\n",
    "        # Frequencies in bpm\n",
    "        hr_pred, hr_gt = calculate_hr(inputs.detach().cpu(), target.detach().cpu(), diff_flag=diff_flag, fs=Fs)\n",
    "        print(f'1 hr_gt={hr_gt}')\n",
    "\n",
    "        inputs = inputs.view(1, -1)\n",
    "        bpm_range = torch.arange(45, 150, dtype=torch.float).to(torch.device('cuda'))\n",
    "        ca = TorchLossComputer.complex_absolute(inputs, Fs, bpm_range)\n",
    "        sa = ca / torch.sum(ca)\n",
    "\n",
    "        target_distribution = [normal_sampling(int(hr_gt), i, std) for i in range(45, 150)]\n",
    "        target_distribution = [i if i > 1e-15 else 1e-15 for i in target_distribution]\n",
    "        target_distribution = torch.Tensor(target_distribution).to(torch.device('cuda'))\n",
    "\n",
    "        hr_gt = torch.tensor(hr_gt - 45).view(1).type(torch.long).to(torch.device('cuda'))\n",
    "        print(f'2 hr_gt={hr_gt}')\n",
    "        print(f'ca={ca}')\n",
    "\n",
    "        return F.cross_entropy(ca, hr_gt), kl_loss(sa, target_distribution)\n",
    "\n",
    "    @staticmethod\n",
    "    def HR_loss(inputs, target, diff_flag, Fs, std):\n",
    "        psd_pred, psd_gt = calculate_psd(inputs.detach().cpu(), target.detach().cpu(), diff_flag=diff_flag, fs=Fs)\n",
    "        print(f'psd_pred={np.argmax(psd_pred)}')\n",
    "        print(f'psd_gt={np.argmax(psd_gt)}')\n",
    "\n",
    "        pred_distribution = [normal_sampling(np.argmax(psd_pred), i, std) for i in range(psd_pred.size)]\n",
    "        pred_distribution = [i if i > 1e-15 else 1e-15 for i in pred_distribution]\n",
    "        pred_distribution = torch.Tensor(pred_distribution).to(torch.device('cuda'))\n",
    "        target_distribution = [normal_sampling(np.argmax(psd_gt), i, std) for i in range(psd_gt.size)]\n",
    "        target_distribution = [i if i > 1e-15 else 1e-15 for i in target_distribution]\n",
    "        target_distribution = torch.Tensor(target_distribution).to(torch.device('cuda'))\n",
    "        return kl_loss(pred_distribution, target_distribution)\n",
    "\n",
    "\n",
    "class Neg_Pearson(nn.Module):  # Pearson range [-1, 1] so if < 0, abs|loss| ; if >0, 1- loss\n",
    "    def __init__(self):\n",
    "        super(Neg_Pearson, self).__init__()\n",
    "\n",
    "    def forward(self, preds, labels):  # all variable operation\n",
    "        loss = 0\n",
    "        for i in range(preds.shape[0]):\n",
    "            sum_x = torch.sum(preds[i])  # x\n",
    "            sum_y = torch.sum(labels[i])  # y\n",
    "            sum_xy = torch.sum(preds[i] * labels[i])  # xy\n",
    "            sum_x2 = torch.sum(torch.pow(preds[i], 2))  # x^2\n",
    "            sum_y2 = torch.sum(torch.pow(labels[i], 2))  # y^2\n",
    "            N = preds.shape[1]\n",
    "            pearson = (N * sum_xy - sum_x * sum_y) / (\n",
    "                torch.sqrt((N * sum_x2 - torch.pow(sum_x, 2)) * (N * sum_y2 - torch.pow(sum_y, 2))))\n",
    "            loss += 1 - pearson\n",
    "\n",
    "        loss = loss / preds.shape[0]\n",
    "        return loss\n",
    "\n",
    "\n",
    "class RhythmFormer_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RhythmFormer_Loss, self).__init__()\n",
    "        self.criterion_Pearson = Neg_Pearson()\n",
    "\n",
    "    def forward(self, pred_ppg, labels, _, FS, diff_flag):\n",
    "        loss_time = self.criterion_Pearson(pred_ppg.view(1, -1), labels.view(1, -1))\n",
    "        loss_CE, _ = TorchLossComputer.Frequency_loss(\n",
    "            pred_ppg.squeeze(-1),\n",
    "            labels.squeeze(-1),\n",
    "            diff_flag=diff_flag,\n",
    "            Fs=FS,\n",
    "            std=3.0)\n",
    "        loss_hr = TorchLossComputer.HR_loss(\n",
    "            pred_ppg.squeeze(-1),\n",
    "            labels.squeeze(-1),\n",
    "            diff_flag=diff_flag,\n",
    "            Fs=FS,\n",
    "            std=3.0)\n",
    "        if torch.isnan(loss_time):\n",
    "            loss_time = 0\n",
    "\n",
    "        loss = 0.2 * loss_time + 1.0 * loss_CE + 1.0 * loss_hr\n",
    "        return loss"
   ],
   "id": "85beb3f5bf15603a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "def normal_sampling_torch(mean, label_k, std):\n",
    "    return torch.exp(-(label_k - mean) ** 2 / (2 * std ** 2)) / (torch.sqrt(torch.tensor(2 * torch.pi)) * std)\n",
    "\n",
    "\n",
    "def filtered_periodogram(\n",
    "        time_series: torch.Tensor,\n",
    "        sampling_rate: int,\n",
    "        min_freq: float = 0,\n",
    "        max_freq: float = float('inf')) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Computes the power spectral density (PSD) of a signal within a given frequency range.\n",
    "    :param time_series: Respiratory signal\n",
    "    :param sampling_rate: Sampling rate\n",
    "    :param min_freq: minimum frequency\n",
    "    :param max_freq: maximum frequency\n",
    "    :return: Frequencies and FFT result\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the power spectral density (PSD) using periodogram\n",
    "    freq = torch.fft.fftfreq(time_series.shape[0], d=1 / sampling_rate)\n",
    "    psd = torch.fft.fft(time_series).abs() ** 2\n",
    "\n",
    "    # Find the indices corresponding to the frequency range\n",
    "    idx = (freq >= min_freq) & (freq <= max_freq)\n",
    "\n",
    "    # Extract the frequencies and PSDs within the specified range\n",
    "    freq_range = freq[idx]\n",
    "    psd_range = psd[idx]\n",
    "\n",
    "    return freq_range, psd_range\n",
    "\n",
    "\n",
    "class HRHybridLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.2, beta=1.0, gamma=1.0):\n",
    "        super(HRHybridLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, prediction, ground_truth):\n",
    "        # Temporal Loss (negative Pearson correlation)\n",
    "        l_time = -self.pearson_correlation(prediction, ground_truth)\n",
    "        # print(f'l_time={l_time}')\n",
    "\n",
    "        # Frequency Loss\n",
    "        # l_freq = self.freqency_loss(prediction, ground_truth)\n",
    "        # print(f'l_time={round(l_time.item(), 3)} l_freq={round(l_freq.item(), 3)}')\n",
    "\n",
    "        # HR Distance Loss\n",
    "        # l_hr = self.hr_distance_loss(prediction, ground_truth)\n",
    "        # print(f'l_hr={l_hr}')\n",
    "        # print(f'l_time={l_time} l_freq={l_freq}')\n",
    "\n",
    "        # Euclidean Distance Loss\n",
    "        l_ec = self.euclidean_distance(prediction, ground_truth)\n",
    "        print(f'l_time={round(l_time.item(), 3)} l_ec={round(l_ec.item(), 3)}')\n",
    "\n",
    "        # Combine losses\n",
    "        # total_loss = self.alpha * l_time + self.beta * l_freq + self.gamma * l_hr\n",
    "        # total_loss = 0.3 * l_time + 0.7 * l_hr\n",
    "\n",
    "        return l_ec\n",
    "\n",
    "    def euclidean_distance(self, prediction: torch.Tensor, ground_truth: torch.Tensor):\n",
    "        freq_pred, pred_psd = filtered_periodogram(prediction, 30, 0.08, 0.6)\n",
    "        freq_gt, gt_psd = filtered_periodogram(ground_truth, 30, 0.08, 0.6)\n",
    "\n",
    "        pred_freq = freq_pred[torch.argmax(pred_psd)].item()\n",
    "        gt_freq = freq_gt[torch.argmax(gt_psd)].item()\n",
    "\n",
    "        # print(f'freq_pred={freq_pred.shape} pred_psd={pred_psd.shape}')\n",
    "        print(f'pred_freq={round(pred_freq, 3)} '\n",
    "              f'gt_freq={round(gt_freq, 3)}')\n",
    "        # print(f'pred_psd={freq_pred}')\n",
    "        # print(f'gt_psd={freq_gt}')\n",
    "\n",
    "        return torch.dist(pred_psd, gt_psd)\n",
    "\n",
    "    def freqency_loss(self, prediction: torch.Tensor, ground_truth: torch.Tensor):\n",
    "        freq_pred, pred_psd = filtered_periodogram(prediction, 30, 0.08, 0.6)\n",
    "        freq_gt, gt_psd = filtered_periodogram(ground_truth, 30, 0.08, 0.6)\n",
    "\n",
    "        pred_freq = freq_pred[torch.argmax(pred_psd)].item()\n",
    "        gt_freq = freq_gt[torch.argmax(gt_psd)].item()\n",
    "\n",
    "        # print(f'freq_pred={freq_pred.shape} pred_psd={pred_psd.shape}')\n",
    "        print(f'pred_freq={round(pred_freq, 3)} '\n",
    "              f'gt_freq={round(gt_freq, 3)}')\n",
    "        # print(f'pred_psd={freq_pred}')\n",
    "        # print(f'gt_psd={freq_gt}')\n",
    "\n",
    "        # return F.cross_entropy(pred_psd.softmax(dim=0), torch.argmax(gt_psd))\n",
    "        return F.cross_entropy(pred_psd.softmax(dim=0), gt_psd)\n",
    "\n",
    "    def pearson_correlation(self, prediction: torch.Tensor, ground_truth: torch.Tensor):\n",
    "        # Compute Pearson correlation\n",
    "        x_mean = torch.mean(prediction)\n",
    "        y_mean = torch.mean(ground_truth)\n",
    "\n",
    "        num = torch.sum((prediction - x_mean) * (ground_truth - y_mean))\n",
    "        den = torch.sqrt(torch.sum((prediction - x_mean) ** 2) * torch.sum((ground_truth - y_mean) ** 2))\n",
    "\n",
    "        return num / den"
   ],
   "id": "42dbd24f8aa76ad1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pred_fake = torch.randn(3600).to(device)\n",
    "gt_fake = torch.randn(3600).to(device)\n",
    "\n",
    "loss_patrick = HRHybridLoss()(pred_fake, gt_fake)\n",
    "print(loss_patrick)"
   ],
   "id": "7501ef3a4edf6cdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "########################",
   "id": "a588ab8131e854b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "\n",
    "# The timestamp is the unique identifier for this training run\n",
    "zone = timezone('Europe/Berlin')\n",
    "timestamp = datetime.now().astimezone(zone).strftime('%Y%m%d_%H%M%S')\n",
    "manifest['timestamp'] = timestamp\n",
    "\n",
    "epochs = 50\n",
    "manifest['epochs'] = epochs\n",
    "\n",
    "loss_fn = HRHybridLoss()\n",
    "manifest['loss_fn'] = 'HRHybridLoss'\n",
    "\n",
    "# learning_rate = 0.00001\n",
    "learning_rate = 0.0001\n",
    "manifest['learning_rate'] = learning_rate"
   ],
   "id": "a2e8a777bc0c7a3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "from respiration.extractor.rhythm_former import RhythmFormer\n",
    "\n",
    "for model_name, model_path in models.items():\n",
    "    model = RhythmFormer()\n",
    "    # Fix model loading: Some key have an extra 'module.' prefix\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    manifest = manifest.copy()\n",
    "    manifest['model'] = model_name\n",
    "    manifest['models'] = []\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    manifest['optimizer'] = 'AdamW'\n",
    "\n",
    "    if model_path is not None:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    model_dir = utils.dir_path(\n",
    "        'models',\n",
    "        'rhythm_former',\n",
    "        timestamp,\n",
    "        model_name,\n",
    "        mkdir=True)\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        training_loader = VitalCamLoader(training, parts=6, device=device)\n",
    "        testing_loader = VitalCamLoader(testing, parts=6, device=device)\n",
    "\n",
    "        train_loss = 0\n",
    "        for (frames, target) in tqdm(training_loader, desc=f'Training'):\n",
    "            frames = preprocess_frames(frames)\n",
    "            # target = target.unsqueeze(0)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(frames).squeeze(0)\n",
    "            # print(f'output.shape={output.shape} target.shape={target.shape}')\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(output, target)\n",
    "            # print(f'loss={loss.item()}')\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            del frames, target, output, loss\n",
    "\n",
    "        testing_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (frames, target) in tqdm(testing_loader, desc=f'Testing'):\n",
    "                frames = preprocess_frames(frames)\n",
    "                # target = target.unsqueeze(0)\n",
    "\n",
    "                output = model(frames).squeeze(0)\n",
    "                loss = loss_fn(output, target)\n",
    "                # print(f'loss={loss.item()}')\n",
    "                testing_loss += loss.item()\n",
    "\n",
    "                del frames, target, output, loss\n",
    "\n",
    "        # Compute the average loss\n",
    "        train_loss /= len(training_loader)\n",
    "        testing_loss /= len(testing_loader)\n",
    "\n",
    "        if testing_loss < best_loss:\n",
    "            best_loss = testing_loss\n",
    "            model_file = utils.file_path(model_dir, f'{model_name}_{epoch}.pth')\n",
    "\n",
    "            manifest['best_loss'] = best_loss\n",
    "            manifest['models'].append({\n",
    "                'epoch': epoch,\n",
    "                'model_file': model_file,\n",
    "                'train_loss': train_loss,\n",
    "                'test_loss': testing_loss,\n",
    "            })\n",
    "\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "\n",
    "        print(f'{model_name}[{epoch + 1}/{epochs}] '\n",
    "              f'train-loss={round(train_loss, 3)} '\n",
    "              f'test-loss={round(testing_loss, 3)}')\n",
    "\n",
    "        # Save the manifest\n",
    "        manifest['epoch'] = epoch\n",
    "        manifest_file = utils.file_path(model_dir, 'manifest.json')\n",
    "        utils.write_json(manifest_file, manifest)"
   ],
   "id": "9fedbf0daa0806cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input = torch.tensor([0.0, 0.001, 10.0, 0.001, 0.001]).softmax(dim=0)\n",
    "target = torch.tensor([0.001, 0.001, 1.5, 5.001, 3.001])\n",
    "output = F.cross_entropy(input, target)\n",
    "# output = F.cross_entropy(input, torch.tensor(3))\n",
    "\n",
    "print(input)\n",
    "print(target)\n",
    "print(output)"
   ],
   "id": "db4dfc3c151c8637",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
