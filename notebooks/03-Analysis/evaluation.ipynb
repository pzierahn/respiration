{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "\n",
    "Steps:\n",
    "1. Harmonize the predictions to have the same format\n",
    "2. Extract the frequencies using a sliding window approach\n",
    "3. Evaluate the performance of the models\n",
    "4. Visualize the results"
   ],
   "id": "858d2eaef54d2b36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 1: Harmonize the predictions",
   "id": "d5de492f4255dbcf"
  },
  {
   "cell_type": "code",
   "id": "db3bfc6b2e01322a",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import respiration.utils as utils\n",
    "\n",
    "signals_dir = utils.dir_path('outputs', 'signals')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raft_file = utils.join_paths(signals_dir, 'raft_predictions.csv')\n",
    "raft_predictions = pd.read_csv(raft_file)\n",
    "raft_predictions['signal'] = raft_predictions['signal_v'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the chest roi predictions\n",
    "raft_predictions = raft_predictions[raft_predictions['roi'] == 'chest']\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "raft_predictions = raft_predictions[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "raft_predictions.head()"
   ],
   "id": "9e7ad8144746a824",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flownet_file = utils.join_paths(signals_dir, 'flownet_predictions.csv')\n",
    "flownet_predictions = pd.read_csv(flownet_file)\n",
    "flownet_predictions['signal'] = flownet_predictions['signal_v'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the chest roi predictions\n",
    "flownet_predictions = flownet_predictions[flownet_predictions['roi'] == 'chest']\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "flownet_predictions = flownet_predictions[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "flownet_predictions.head()"
   ],
   "id": "2a413445397940c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pretrained_file = utils.join_paths(signals_dir, 'pretrained_predictions.csv')\n",
    "pretrained_predictions = pd.read_csv(pretrained_file)\n",
    "pretrained_predictions['signal'] = pretrained_predictions['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "pretrained_predictions = pretrained_predictions[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "pretrained_predictions.head()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lucas_kanade_file = utils.join_paths(signals_dir, 'lucas_kanade.csv')\n",
    "lucas_kanade = pd.read_csv(lucas_kanade_file)\n",
    "lucas_kanade['signal'] = lucas_kanade['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Rename column method to model\n",
    "lucas_kanade.rename(columns={'method': 'model'}, inplace=True)\n",
    "\n",
    "# Remove all the rows that have a signal with a length of 0\n",
    "lucas_kanade = lucas_kanade[lucas_kanade['grey'] == False]\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "lucas_kanade = lucas_kanade[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "lucas_kanade.head()"
   ],
   "id": "f995d2bcc90e1731",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pixel_intensity_file = utils.join_paths(signals_dir, 'pixel_intensity.csv')\n",
    "pixel_intensity = pd.read_csv(pixel_intensity_file)\n",
    "pixel_intensity['signal'] = pixel_intensity['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Rename column method to model\n",
    "pixel_intensity.rename(columns={'method': 'model'}, inplace=True)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "pixel_intensity = pixel_intensity[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "pixel_intensity.head()"
   ],
   "id": "20bae0c2d2b60800",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "r_ppg_path = utils.join_paths(signals_dir, 'r_ppg_predictions.csv')\n",
    "\n",
    "r_ppg_prediction = pd.read_csv(r_ppg_path)\n",
    "r_ppg_prediction['signal'] = r_ppg_prediction['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "r_ppg_prediction = r_ppg_prediction[['subject', 'setting', 'model', 'signal']]\n",
    "r_ppg_prediction.head()"
   ],
   "id": "d4fba7688e368e8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transformer_path = utils.join_paths(signals_dir, 'transformer_predictions.csv')\n",
    "\n",
    "transformer_prediction = pd.read_csv(transformer_path)\n",
    "transformer_prediction['signal'] = transformer_prediction['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Add a tf_ prefix to the model names\n",
    "transformer_prediction['model'] = 'tf_' + transformer_prediction['model']\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "transformer_prediction = transformer_prediction[['subject', 'setting', 'model', 'signal']]\n",
    "transformer_prediction.head()"
   ],
   "id": "3ff4d484569eeff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# The random signal is used as a baseline to see how well the models perform against a random predictions\n",
    "#\n",
    "random_path = utils.join_paths(signals_dir, 'random_predictions.csv')\n",
    "\n",
    "random_prediction = pd.read_csv(random_path)\n",
    "random_prediction['signal'] = random_prediction['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "random_prediction = random_prediction[['subject', 'setting', 'model', 'signal']]\n",
    "random_prediction.head()"
   ],
   "id": "c980aed7c7a98e46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhythm_former_path = utils.join_paths(signals_dir, 'rhythm_former.csv')\n",
    "\n",
    "rhythm_former = pd.read_csv(rhythm_former_path)\n",
    "rhythm_former['signal'] = rhythm_former['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "rhythm_former = rhythm_former[['subject', 'setting', 'model', 'signal']]\n",
    "rhythm_former.head()"
   ],
   "id": "ff91bd9f4150474f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "efficient_phys_path = utils.join_paths(signals_dir, 'efficient_phys_predictions.csv')\n",
    "\n",
    "efficient_phys_predictions = pd.read_csv(efficient_phys_path)\n",
    "efficient_phys_predictions['signal'] = efficient_phys_predictions['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "efficient_phys_predictions = efficient_phys_predictions[['subject', 'setting', 'model', 'signal']]\n",
    "efficient_phys_predictions.head()"
   ],
   "id": "a2d1675572d3ff79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = pd.concat([\n",
    "    raft_predictions,\n",
    "    flownet_predictions,\n",
    "    pretrained_predictions,\n",
    "    lucas_kanade,\n",
    "    pixel_intensity,\n",
    "    r_ppg_prediction,\n",
    "    transformer_prediction,\n",
    "    random_prediction,\n",
    "    rhythm_former,\n",
    "    efficient_phys_predictions,\n",
    "])\n",
    "len(predictions)"
   ],
   "id": "26fd22df832dffa8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show all models\n",
    "predictions['model'].unique()"
   ],
   "id": "d82d14565cc8fd72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2: Extract the frequencies using a sliding window approach",
   "id": "37e70d5e3a50c222"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "sample_rate = 30\n",
    "dataset = VitalCamSet()"
   ],
   "id": "42dfbd471b70b5f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "import respiration.analysis as analysis\n",
    "\n",
    "experiment_analysis = analysis.Analysis(\n",
    "    sample_rate=sample_rate,\n",
    "    lowpass=0.1,\n",
    "    highpass=0.5,\n",
    ")\n",
    "\n",
    "for idx, row in tqdm(predictions.iterrows(), total=len(predictions)):\n",
    "    subject, setting = row['subject'], row['setting']\n",
    "    prediction = row['signal']\n",
    "    model = row['model']\n",
    "    gt_signal = dataset.get_breathing_signal(subject, setting)\n",
    "\n",
    "    # Cut the gt_signal to have the same length as the prediction\n",
    "    gt_signal = gt_signal[:len(prediction)]\n",
    "\n",
    "    experiment_analysis.add_data(model, prediction, gt_signal)"
   ],
   "id": "182a18fc797f0313",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "analysis_dir = utils.dir_path('outputs', 'analysis')",
   "id": "3670af9c6253b56a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_table = experiment_analysis.metrics_df()\n",
    "\n",
    "# Fill nan values with 0\n",
    "results_table = results_table.fillna(0)\n",
    "\n",
    "# Calculate the MAE and RMSE in beats per minute (bpm)\n",
    "results_table['MAE'] = results_table['MAE'].apply(lambda x: round(x * 60, 3))\n",
    "results_table['RMSE'] = results_table['RMSE'].apply(lambda x: round(x * 60, 3))\n",
    "\n",
    "results_table.to_csv(utils.join_paths(analysis_dir, 'metrics.csv'), index=False)\n",
    "results_table"
   ],
   "id": "2b2b3132ef86d75e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results_table.groupby('method')['PCC'].mean().reset_index().sort_values('PCC')",
   "id": "8d5ace4c6f7a45cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results_table['model'].unique()",
   "id": "868f9a5bd42ef2e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_selection = [\n",
    "    \"raft_small\",\n",
    "    \"raft_large\",\n",
    "    \"lucas_kanade\",\n",
    "    # \"FlowNet2S\",\n",
    "    \"FlowNet2CS\",\n",
    "    \"big_small\",\n",
    "    \"mtts_can\",\n",
    "    \"UBFC_cross_RhythmFormer\",\n",
    "    \"SCAMPS_TSCAN\",\n",
    "    \"random\",\n",
    "    \"mtts_can\",\n",
    "    \"pixel_intensity_grey\",\n",
    "    \"SCAMPS_DeepPhys\",\n",
    "    \"PURE_EfficientPhys\",\n",
    "    \"tf_20240729_195756\",\n",
    "    \"RF_20240802_155121\",\n",
    "    \"RF_20240805_200748\",\n",
    "]"
   ],
   "id": "6b6c547f6b5c5ded",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "points = {}\n",
    "\n",
    "for _, row in results_table.iterrows():\n",
    "    model_name = row['model']\n",
    "    if model_name not in model_selection:\n",
    "        continue\n",
    "\n",
    "    method = row['method'].upper()\n",
    "    pcc = row['PCC']\n",
    "    mae = row['MAE']\n",
    "\n",
    "    if model_name not in points:\n",
    "        points[model_name] = {}\n",
    "\n",
    "    points[model_name]['model'] = model_name\n",
    "    points[model_name][method + '_MAE'] = mae\n",
    "    points[model_name][method + '_PCC'] = abs(pcc)\n",
    "\n",
    "points = pd.DataFrame(points.values())\n",
    "points"
   ],
   "id": "e8c9b33f0b4df69f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rename = {\n",
    "    'PURE_EfficientPhys': 'EfficientPhys',\n",
    "    'SCAMPS_DeepPhys': 'DeepPhys',\n",
    "    'SCAMPS_TSCAN': 'TS-CAN',\n",
    "    'MMPD_intra_RhythmFormer': 'Rhythm Former (original)',\n",
    "    'UBFC_cross_RhythmFormer': 'Rhythm Former (original)',\n",
    "    'tf_20240728_114332': 'SimpleViT (20240728_114332)',\n",
    "    'tf_20240729_195756': 'SimpleViT (20240729_195756)',\n",
    "    'RF_20240726_104536': 'Respiration Rhythm Former (Normal)',\n",
    "    'RF_20240801_124757': 'Respiration Rhythm Former (Normal)',\n",
    "    'RF_20240802_155121': 'Respiration Rhythm Former (Normal)',\n",
    "    'RF_20240805_200748': 'Respiration Rhythm Former (Faces)',\n",
    "}\n",
    "\n",
    "points['model'] = points['model'].apply(lambda x: rename[x] if x in rename else x)"
   ],
   "id": "93e566a78aad3215",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the MAE and PCC for the psd method\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Scatter the MAE and PCC for the different models\n",
    "sns.scatterplot(\n",
    "    data=points,\n",
    "    # x='NFCP_MAE',\n",
    "    # x='PK_MAE',\n",
    "    # y='PSD_MAE',\n",
    "    # x='nfcp_MAE',\n",
    "    # y='nfcp_PCC',\n",
    "    # x='nfcp_MAE',\n",
    "    # y='nfcp_PCC',\n",
    "    x='PSD_MAE',\n",
    "    y='PSD_PCC',\n",
    "    s=250,\n",
    "    style='model',\n",
    "    hue='model',\n",
    ")\n",
    "\n",
    "# plt.xlabel('MAE (PK)')\n",
    "# plt.ylabel('MAE (PSD)')\n",
    "plt.xlabel('MAE (BPM)')\n",
    "plt.ylabel('Correlation')\n",
    "plt.title('MAE and Pearson Correlation for the different models')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Set the dimensions of the plot\n",
    "# plt.xlim(0, 8)\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# Place the legend outside the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Disable the legend\n",
    "# plt.legend().remove()\n",
    "\n",
    "plt.show()"
   ],
   "id": "a4d08604c3f47702",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3: Score the performance of the models",
   "id": "efc48d8eb0af948b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_table_x = results_table.copy()\n",
    "\n",
    "# Calculate the PCC in absolute values\n",
    "results_table_x['PCC'] = results_table_x['PCC'].apply(lambda x: abs(x))\n",
    "\n",
    "# Remove the cp method, because we use the improved nfcp method\n",
    "results_table_x = results_table_x[(results_table_x['method'] == 'pk') |\n",
    "                                  (results_table_x['method'] == 'psd')]\n",
    "\n",
    "# Calculate the average RMSE for each model\n",
    "average_metric = results_table_x.groupby('model')['MAE'].mean().reset_index()\n",
    "average_metric['MAE'] = average_metric['MAE'].apply(lambda x: round(x, 3))\n",
    "average_metric['MAE_std'] = results_table_x.groupby('model')['MAE'].std().values\n",
    "\n",
    "# Add the averaged RMSE for each model\n",
    "average_metric['RMSE'] = results_table_x.groupby('model')['RMSE'].mean().values\n",
    "average_metric['RMSE'] = average_metric['RMSE'].apply(lambda x: round(x, 3))\n",
    "average_metric['RMSE_std'] = results_table_x.groupby('model')['RMSE'].std().values\n",
    "\n",
    "# Add the averaged PCC for each model\n",
    "average_metric['PCC'] = results_table_x.groupby('model')['PCC'].mean().values\n",
    "average_metric['PCC'] = average_metric['PCC'].apply(lambda x: round(x, 3))\n",
    "average_metric['p-value'] = results_table_x.groupby('model')['PCC-p-value'].mean().values\n",
    "average_metric['p-value'] = average_metric['p-value'].apply(lambda x: round(x, 3))\n",
    "\n",
    "# Store the results\n",
    "average_metric.to_csv(utils.join_paths(analysis_dir, 'average_metrics.csv'), index=False)\n",
    "\n",
    "average_metric"
   ],
   "id": "55a0e06135fdf3d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "average_metric_select = average_metric[average_metric['model'].isin(model_selection)]\n",
    "\n",
    "# Rename the models\n",
    "average_metric_select['model'] = average_metric_select['model'].apply(lambda x: rename[x] if x in rename else x)\n",
    "\n",
    "# Scatter the MAE and PCC for the different models\n",
    "sns.scatterplot(\n",
    "    data=average_metric_select,\n",
    "    # x='NFCP_MAE',\n",
    "    x='MAE',\n",
    "    y='PCC',\n",
    "    # x='nfcp_MAE',\n",
    "    # y='nfcp_PCC',\n",
    "    # x='nfcp_MAE',\n",
    "    # y='nfcp_PCC',\n",
    "    # x='PSD_MAE',\n",
    "    # y='PSD_PCC',\n",
    "    s=250,\n",
    "    style='model',\n",
    "    hue='model',\n",
    ")\n",
    "\n",
    "plt.xlabel('MAE')\n",
    "plt.ylabel('PCC')\n",
    "# plt.xlabel('MAE (BPM)')\n",
    "# plt.ylabel('Correlation')\n",
    "plt.title('MAE and Pearson Correlation for the different models')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Set the dimensions of the plot\n",
    "# plt.xlim(0, 8)\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# Place the legend outside the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Disable the legend\n",
    "# plt.legend().remove()\n",
    "\n",
    "plt.show()"
   ],
   "id": "806bd35a202899ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the MAE for the following models\n",
    "xxx = results_table_x[results_table_x['model'].isin(model_selection)]\n",
    "\n",
    "# Sort the models by the average MAE\n",
    "xxx = xxx.sort_values('MAE')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Boxplot with std\n",
    "sns.boxplot(data=xxx, x='model', y='MAE')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('MAE (bpm)')\n",
    "plt.xlabel('Model')\n",
    "plt.title('MAE of the different models')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "id": "81dfb8b260dc1e87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model = \"lucas_kanade\"\n",
    "model = \"RF_20240802_155121\"\n",
    "# model = \"MMPD_intra_RhythmFormer\"\n",
    "\n",
    "# Create a bland-altman plot for the following models\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "for idx, metric in enumerate([\"psd\", \"pk\", \"cp\", \"nfcp\"]):\n",
    "    preds = experiment_analysis.prediction_metrics[model][metric]\n",
    "    gts = experiment_analysis.ground_truth_metrics[model][metric]\n",
    "\n",
    "    # Transform the values from Hz to beats per minute\n",
    "    preds = preds * 60\n",
    "    gts = gts * 60\n",
    "\n",
    "    # Scatter plot\n",
    "    axs[idx].scatter(gts, preds, label=metric)\n",
    "    axs[idx].set_title(f'{metric.upper()}')\n",
    "\n",
    "    pcc = np.corrcoef(gts, preds)[0, 1]\n",
    "    axs[idx].text(0.1, 0.9, f'PCC: {round(pcc, 3)}', transform=axs[idx].transAxes)\n",
    "    # Add a trend line\n",
    "    axs[idx].plot(np.unique(gts), np.poly1d(np.polyfit(gts, preds, 1))(np.unique(gts)), color='red')\n",
    "\n",
    "    # Show the range 0 to 35 for the x- and y-axis\n",
    "    axs[idx].set_xlim(0, 45)\n",
    "    axs[idx].set_ylim(0, 45)\n",
    "\n",
    "    # Name the x- and y-axis\n",
    "    axs[idx].set_xlabel('Ground truth (bpm)')\n",
    "    axs[idx].set_ylabel('Prediction (bpm)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6faae9b5b1093544",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for idx, metric in enumerate([\"psd\", \"pk\", \"cp\", \"nfcp\"]):\n",
    "    gts = experiment_analysis.ground_truth_metrics[model][metric].copy() * 60\n",
    "    pred = experiment_analysis.prediction_metrics[model][metric].copy() * 60\n",
    "\n",
    "    print(f'{metric:4s} gt   mean={gts.mean():.1f} std={gts.std():.1f}')\n",
    "    # print(f'{metric:4s} pred mean={pred.mean():.1f} std={pred.std():.1f}')"
   ],
   "id": "3506610e9bf4425d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "psd_gts = experiment_analysis.ground_truth_metrics[model]['psd'].copy() * 60\n",
    "pk_gts = experiment_analysis.ground_truth_metrics[model]['pk'].copy() * 60\n",
    "\n",
    "diff = abs(psd_gts - pk_gts)\n",
    "diff.mean(), diff.std()"
   ],
   "id": "13a275b1962340f4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
