{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extract respiratory signals with RAFT\n",
    "\n",
    "Recurrent All-Pairs Field Transforms (RAFT) is a deep learning model for optical flow estimation. The optical flow directions and magnitudes can be used to extract respiratory signals from videos. This notebook demonstrates how to use RAFT to extract respiratory signals from videos."
   ],
   "id": "e931c39f16bae87e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "\n",
    "subject = 'Proband11'\n",
    "setting = '101_natural_lighting'\n",
    "\n",
    "video_path = dataset.get_video_path(subject, setting)"
   ],
   "id": "3f5527a9bf000",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load the RAFT model",
   "id": "5b39d80a238d40de"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import respiration.utils as utils\n",
    "import respiration.extractor.raft as raft\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "model = raft.load_model('raft_small', device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract optical flow from the video",
   "id": "b67acd67436fb434"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "param = utils.get_video_params(video_path)\n",
    "# Only get the first 30 seconds of the video\n",
    "param.num_frames = param.fps * 20\n",
    "\n",
    "# Number of frames that are processed at once\n",
    "batch_size = 20\n",
    "batches = math.ceil(param.num_frames / (batch_size // 2))\n",
    "\n",
    "# Store the optical flows vectors (N, 2, H, W)\n",
    "optical_flows = np.zeros((param.num_frames - 1, 2, param.height, param.width), dtype=np.float32)\n",
    "\n",
    "# Extract the optical flow from the video in batches\n",
    "for batch in tqdm(range(0, batches)):\n",
    "    start = (batch_size // 2) * batch\n",
    "    num_frames = min(start + batch_size, param.num_frames) - start\n",
    "    chunk, _ = utils.read_video_rgb(video_path, num_frames, start)\n",
    "    chunk = raft.preprocess(chunk, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        flows = model(chunk[:-1], chunk[1:])\n",
    "\n",
    "    # Garbage collect...\n",
    "    del chunk\n",
    "\n",
    "    # Only keep the last flow iteration\n",
    "    flows = flows[-1]\n",
    "\n",
    "    for idx in range(flows.shape[0]):\n",
    "        # Add the optical flow to the numpy array\n",
    "        optical_flows[start + idx] = flows[idx].cpu().numpy()"
   ],
   "id": "ef2039ce2b562fa8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize the optical flow",
   "id": "21f8ecfff969c042"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "figure_dir = utils.dir_path('outputs', 'figures', 'raft', mkdir=True)",
   "id": "73ab1e6b51bb90c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "frames, _ = utils.read_video_rgb(video_path, 1, 1)\n",
    "arrow_frame = raft.draw_flow(frames[0], optical_flows[0])\n",
    "flow_frame = raft.image_from_flow(optical_flows[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 8))\n",
    "ax[0].imshow(arrow_frame)\n",
    "ax[0].set_title('Optical flow arrows')\n",
    "ax[1].imshow(flow_frame)\n",
    "ax[1].set_title('Optical flow magnitude')\n",
    "\n",
    "utils.savefig(fig, figure_dir, 'optical_flow')"
   ],
   "id": "55a7216db8ee3b34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Extract the respiratory signal\n",
    "\n",
    "1. Find the region of interest (ROI) on the chest\n",
    "2. Calculate the motion magnitude in the ROI\n",
    "3. Plot the motion magnitude over time"
   ],
   "id": "874aecbbb53b00ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.roi as roi\n",
    "\n",
    "# Find the chest region\n",
    "x, y, w, h = roi.detect_chest(frames[0])\n",
    "\n",
    "# Get only the optical flows in the chest region\n",
    "roi_flows = optical_flows[:, :, y:y + h, x:x + w]\n",
    "\n",
    "# Calculate motion magnitude by squaring the x and y components and taking the square root\n",
    "# magnitudes = np.sqrt(roi_flows[:, 0] ** 2 + roi_flows[:, 1] ** 2)\n",
    "magnitudes = np.sqrt(roi_flows[:, 1] ** 2)"
   ],
   "id": "8aa5cd3d30abeb14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean_curve = np.mean(magnitudes, axis=(1, 2))\n",
    "std_curve = np.std(magnitudes, axis=(1, 2))"
   ],
   "id": "8d213c646c6e4318",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "ax.plot(mean_curve, label='Mean')\n",
    "ax.fill_between(\n",
    "    np.arange(len(mean_curve)),\n",
    "    mean_curve - std_curve,\n",
    "    mean_curve + std_curve,\n",
    "    alpha=0.3,\n",
    "    label='Standard deviation')\n",
    "\n",
    "ax.set_title('Motion magnitude in the ROI')\n",
    "ax.set_xlabel('Frame')\n",
    "ax.set_ylabel('Motion magnitude')\n",
    "\n",
    "utils.savefig(fig, figure_dir, 'roi_magnitudes')"
   ],
   "id": "3f348a0c6c9a6316",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compare the ground truth and prediction",
   "id": "5d5ad00982010dcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lowpass = 0.1\n",
    "highpass = 0.5"
   ],
   "id": "8573ed78d25595c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.analysis as analysis\n",
    "\n",
    "# Filter and normalize the ground truth signal\n",
    "ground_truth = dataset.get_breathing_signal(subject, setting)\n",
    "ground_truth = ground_truth[:param.num_frames]\n",
    "ground_truth = analysis.normalize_signal(ground_truth)\n",
    "ground_truth = analysis.butterworth_filter(ground_truth, param.fps, lowpass, highpass)\n",
    "\n",
    "# Filter and normalize the predicted signal\n",
    "predicted = analysis.normalize_signal(mean_curve)\n",
    "predicted = analysis.butterworth_filter(predicted, param.fps, lowpass, highpass)"
   ],
   "id": "3c61efa80d5bddd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(20, 8))\n",
    "ax[0].plot(ground_truth, label='Ground truth')\n",
    "ax[0].set_title('Ground truth')\n",
    "ax[0].set_xlabel('Frame')\n",
    "ax[0].set_ylabel('Normalized signal')\n",
    "\n",
    "ax[1].plot(predicted, label='Predicted')\n",
    "ax[1].set_title('Predicted')\n",
    "ax[1].set_xlabel('Frame')\n",
    "ax[1].set_ylabel('Normalized signal')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "utils.savefig(fig, figure_dir, 'comparison')"
   ],
   "id": "131eb3acf778b7ad",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
