{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "\n",
    "Steps:\n",
    "1. Harmonize the predictions to have the same format\n",
    "2. Extract the frequencies using a sliding window approach\n",
    "3. Evaluate the performance of the models\n",
    "4. Visualize the results"
   ],
   "id": "858d2eaef54d2b36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 1: Harmonize the predictions",
   "id": "d5de492f4255dbcf"
  },
  {
   "cell_type": "code",
   "id": "db3bfc6b2e01322a",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import respiration.utils as utils\n",
    "\n",
    "signals_dir = utils.dir_path('outputs', 'signals')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raft_file = utils.join_paths(signals_dir, 'raft_predictions.csv')\n",
    "raft_predictions = pd.read_csv(raft_file)\n",
    "raft_predictions['signal'] = raft_predictions['signal_v'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the chest roi predictions\n",
    "raft_predictions = raft_predictions[raft_predictions['roi'] == 'chest']\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "raft_predictions = raft_predictions[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "raft_predictions.head()"
   ],
   "id": "9e7ad8144746a824",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flownet_file = utils.join_paths(signals_dir, 'flownet_predictions.csv')\n",
    "flownet_predictions = pd.read_csv(flownet_file)\n",
    "flownet_predictions['signal'] = flownet_predictions['signal_v'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the chest roi predictions\n",
    "flownet_predictions = flownet_predictions[flownet_predictions['roi'] == 'chest']\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "flownet_predictions = flownet_predictions[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "flownet_predictions.head()"
   ],
   "id": "2a413445397940c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pretrained_file = utils.join_paths(signals_dir, 'pretrained_predictions.csv')\n",
    "pretrained_predictions = pd.read_csv(pretrained_file)\n",
    "pretrained_predictions['signal'] = pretrained_predictions['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "pretrained_predictions = pretrained_predictions[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "pretrained_predictions.head()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lucas_kanade_file = utils.join_paths(signals_dir, 'lucas_kanade.csv')\n",
    "lucas_kanade = pd.read_csv(lucas_kanade_file)\n",
    "lucas_kanade['signal'] = lucas_kanade['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Rename column method to model\n",
    "lucas_kanade.rename(columns={'method': 'model'}, inplace=True)\n",
    "\n",
    "# Remove all the rows that have a signal with a length of 0\n",
    "lucas_kanade = lucas_kanade[lucas_kanade['grey'] == False]\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "lucas_kanade = lucas_kanade[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "lucas_kanade.head()"
   ],
   "id": "f995d2bcc90e1731",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pixel_intensity_file = utils.join_paths(signals_dir, 'pixel_intensity.csv')\n",
    "pixel_intensity = pd.read_csv(pixel_intensity_file)\n",
    "pixel_intensity['signal'] = pixel_intensity['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Rename column method to model\n",
    "pixel_intensity.rename(columns={'method': 'model'}, inplace=True)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "pixel_intensity = pixel_intensity[['subject', 'setting', 'model', 'signal']]\n",
    "\n",
    "pixel_intensity.head()"
   ],
   "id": "20bae0c2d2b60800",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "r_ppg_path = utils.join_paths(signals_dir, 'r_ppg_predictions.csv')\n",
    "\n",
    "r_ppg_prediction = pd.read_csv(r_ppg_path)\n",
    "r_ppg_prediction['signal'] = r_ppg_prediction['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "r_ppg_prediction = r_ppg_prediction[['subject', 'setting', 'model', 'signal']]\n",
    "r_ppg_prediction.head()"
   ],
   "id": "d4fba7688e368e8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transformer_path = utils.join_paths(signals_dir, 'transformer_predictions.csv')\n",
    "\n",
    "transformer_prediction = pd.read_csv(transformer_path)\n",
    "transformer_prediction['signal'] = transformer_prediction['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Add a tf_ prefix to the model names\n",
    "transformer_prediction['model'] = 'tf_' + transformer_prediction['model']\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "transformer_prediction = transformer_prediction[['subject', 'setting', 'model', 'signal']]\n",
    "transformer_prediction.head()"
   ],
   "id": "3ff4d484569eeff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# The random signal is used as a baseline to see how well the models perform against a random predictions\n",
    "#\n",
    "random_path = utils.join_paths(signals_dir, 'random_predictions.csv')\n",
    "\n",
    "random_prediction = pd.read_csv(random_path)\n",
    "random_prediction['signal'] = random_prediction['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "random_prediction = random_prediction[['subject', 'setting', 'model', 'signal']]\n",
    "random_prediction.head()"
   ],
   "id": "c980aed7c7a98e46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhythm_former_path = utils.join_paths(signals_dir, 'rhythm_former.csv')\n",
    "\n",
    "rhythm_former = pd.read_csv(rhythm_former_path)\n",
    "rhythm_former['signal'] = rhythm_former['signal'].apply(eval).apply(np.array)\n",
    "\n",
    "# Only keep the columns that are needed\n",
    "rhythm_former = rhythm_former[['subject', 'setting', 'model', 'signal']]\n",
    "rhythm_former.head()"
   ],
   "id": "ff91bd9f4150474f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = pd.concat([\n",
    "    raft_predictions,\n",
    "    flownet_predictions,\n",
    "    pretrained_predictions,\n",
    "    lucas_kanade,\n",
    "    pixel_intensity,\n",
    "    r_ppg_prediction,\n",
    "    transformer_prediction,\n",
    "    random_prediction,\n",
    "    rhythm_former,\n",
    "])\n",
    "len(predictions)"
   ],
   "id": "26fd22df832dffa8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show all models\n",
    "predictions['model'].unique()"
   ],
   "id": "d82d14565cc8fd72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2: Extract the frequencies using a sliding window approach",
   "id": "37e70d5e3a50c222"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()"
   ],
   "id": "42dfbd471b70b5f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "subject = 'Proband22'\n",
    "setting = '101_natural_lighting'"
   ],
   "id": "23a3569739b6f56e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sampling_rate = 30\n",
    "lowpass = 0.1\n",
    "highpass = 0.5"
   ],
   "id": "a447e4d03c48556b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.analysis import (\n",
    "    butterworth_filter,\n",
    "    normalize_signal,\n",
    "    detrend_tarvainen,\n",
    ")\n",
    "\n",
    "from scipy.signal import detrend\n",
    "\n",
    "models = [\n",
    "    # 'lucas_kanade',\n",
    "    'RF_20240802_155121',\n",
    "    # 'RF_20240726_104536',\n",
    "    # 'raft_small',\n",
    "    # 'pixel_intensity_grey',\n",
    "    # 'tf_20240729_195756',\n",
    "    # 'MMPD_intra_RhythmFormer',\n",
    "    # 'mtts_can',\n",
    "    # 'big_small',\n",
    "]\n",
    "\n",
    "signals = []\n",
    "\n",
    "for model in models:\n",
    "    prediction_x = predictions[\n",
    "        (predictions['subject'] == subject) &\n",
    "        (predictions['setting'] == setting) &\n",
    "        (predictions['model'] == model)].iloc[0]['signal']\n",
    "\n",
    "    print(f'{model}: {prediction_x.shape}')\n",
    "\n",
    "    # Normalize the signals\n",
    "    prediction = normalize_signal(prediction_x)\n",
    "\n",
    "    # Filter the signals\n",
    "    prediction = butterworth_filter(prediction, sampling_rate, lowpass, highpass)\n",
    "\n",
    "    # Add the signals to the list\n",
    "    signals.append({\n",
    "        'label': model,\n",
    "        'signal': prediction,\n",
    "        'signal_x': prediction_x,\n",
    "    })"
   ],
   "id": "6453d70d837bad2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the ground truth signal\n",
    "gt_signal_xxx = dataset.get_breathing_signal(subject, setting)\n",
    "gt_signal = dataset.get_breathing_signal(subject, setting)\n",
    "gt_signal = normalize_signal(gt_signal)\n",
    "gt_signal = butterworth_filter(gt_signal, sampling_rate, lowpass, highpass)"
   ],
   "id": "159da1bea75c3e7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the gt_signal_xxx signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(gt_signal_xxx)\n",
    "plt.title('Ground truth signal')\n",
    "plt.show()"
   ],
   "id": "462021326677e0c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.analysis import frequency_from_psd\n",
    "\n",
    "gt_freq = frequency_from_psd(gt_signal, sampling_rate)\n",
    "print(f'Ground truth signal {gt_freq:.2f} ({gt_freq * 60:.2f} bpm)')"
   ],
   "id": "3f36ed30e2ec9785",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the ground truth signal spectrogram\n",
    "from scipy.signal import spectrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, t, Sxx = spectrogram(\n",
    "    gt_signal,\n",
    "    fs=sampling_rate,\n",
    "    nperseg=200,\n",
    "    # window=('tukey', 5.0),\n",
    "    # mode=\"magnitude\",\n",
    ")\n",
    "print(f'f.shape: {f.shape}')\n",
    "print(f't.shape: {t.shape}')\n",
    "print(f'Sxx.shape: {Sxx.shape}')\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "# plt.pcolormesh(t, f, 10 * np.log10(Sxx), shading='gouraud')\n",
    "plt.pcolormesh(t, f, Sxx)\n",
    "# plt.pcolormesh(t, f, Sxx, cmap='viridis')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "\n",
    "# Show the range 0 - 1 Hz\n",
    "plt.ylim(0, 0.6)\n",
    "\n",
    "# Add a grid\n",
    "# plt.grid()\n",
    "\n",
    "plt.title('Spectrogram of the ground truth signal')\n",
    "plt.show()"
   ],
   "id": "b29570d78716d79a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the max Sxx value\n",
    "max_Sxx = np.max(Sxx, axis=0)\n",
    "\n",
    "# Replace the max values with the frequency\n",
    "values = np.array([f[np.argmax(Sxx[:, i])] for i in range(len(max_Sxx))])\n",
    "\n",
    "print(f'Mean: {np.mean(values)}')\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(t, values)\n",
    "plt.title('Max Sxx value')\n",
    "plt.ylim(0, 0.6)\n",
    "plt.show()"
   ],
   "id": "19096bb162e1b787",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Generate a sample signal (e.g., a sine wave)\n",
    "gt_signal_torch = torch.Tensor(gt_signal.copy())\n",
    "\n",
    "# Step 2: Define parameters for the STFT\n",
    "n_fft = 256  # Number of FFT points\n",
    "hop_length = 30  # Number of samples between successive frames (overlap)\n",
    "win_length = n_fft  # Window length\n",
    "window = torch.hann_window(win_length)  # Hanning window\n",
    "\n",
    "stft = torch.stft(\n",
    "    gt_signal_torch,\n",
    "    n_fft=n_fft,\n",
    "    hop_length=hop_length,\n",
    "    win_length=win_length,\n",
    "    window=window,\n",
    "    return_complex=True,\n",
    ")\n",
    "print('stft.shape', stft.shape)\n",
    "\n",
    "frequencies = torch.fft.fftfreq(n_fft, 1 / sampling_rate)[:n_fft // 2 + 1]  # Only keep non-negative frequencies\n",
    "print('frequencies.shape', frequencies.shape)\n",
    "\n",
    "times = torch.arange(stft.size(1)) * hop_length / sampling_rate\n",
    "print('times.shape', times.shape)\n",
    "\n",
    "spectrogram = torch.abs(stft)\n",
    "print('spectrogram.shape', spectrogram.shape)\n",
    "\n",
    "# Convert to dB scale (optional)\n",
    "spectrogram_db = 10 * torch.log10(spectrogram + 1e-10)  # Add a small value to avoid log(0)\n",
    "\n",
    "# Step 5: Plot the spectrogram\n",
    "plt.figure(figsize=(20, 5))\n",
    "# plt.pcolormesh(spectrogram.numpy(), shading='gouraud')\n",
    "plt.pcolormesh(times.numpy(), frequencies.numpy(), spectrogram_db.numpy(), cmap='viridis')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time Frame')\n",
    "plt.title('Spectrogram')\n",
    "# plt.ylim(0, 10)\n",
    "plt.show()"
   ],
   "id": "24facb5263df3e52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "fs = 30  # Sampling frequency in Hz\n",
    "t = torch.linspace(0, 1, 3600)\n",
    "x = torch.sin(2 * np.pi * 5 * t) * torch.sin(2 * np.pi * 2 * t)\n",
    "\n",
    "# STFT parameters\n",
    "n_fft = 256  # Number of FFT points\n",
    "hop_length = fs  # Number of samples between successive frames\n",
    "win_length = n_fft  # Window length\n",
    "window = torch.hann_window(win_length)\n",
    "\n",
    "# Compute the STFT\n",
    "stft = torch.stft(x, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window, return_complex=True)\n",
    "print('stft.shape', stft.shape)\n",
    "\n",
    "# Compute the magnitude spectrogram\n",
    "spectrogram = torch.abs(stft)\n",
    "print('spectrogram.shape', spectrogram.shape)\n",
    "\n",
    "# Convert to dB scale (optional)\n",
    "spectrogram_db = 10 * torch.log10(spectrogram + 1e-10)  # Add a small value to avoid log(0)\n",
    "\n",
    "# Calculate frequency and time bins\n",
    "frequencies = torch.fft.fftfreq(n_fft, 1 / fs)[:n_fft//2 + 1]  # Only keep non-negative frequencies\n",
    "print('frequencies.shape', frequencies.shape)\n",
    "times = torch.arange(stft.size(1)) * hop_length / fs\n",
    "print('times.shape', times.shape)\n",
    "\n",
    "# Plot the spectrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pcolormesh(times.numpy(), frequencies.numpy(), spectrogram_db.numpy(), cmap='viridis', shading='gouraud')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.title('Spectrogram')\n",
    "plt.show()"
   ],
   "id": "ab91cea2840ed655",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T"
   ],
   "id": "815a79c6ff6288",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the Spectrogram transform\n",
    "spectrogram_transform = T.Spectrogram(\n",
    "    n_fft=200,        # number of FFT bins\n",
    "    win_length=None,  # window size, default to n_fft\n",
    "    hop_length=30,   # hop length between frames\n",
    "    power=2.0         # power to scale the magnitude\n",
    ")\n",
    "\n",
    "# Apply the transform to the waveform\n",
    "spectrogram = spectrogram_transform(gt_signal_torch)\n",
    "print(spectrogram.shape)"
   ],
   "id": "efb9f50bf56a421b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
