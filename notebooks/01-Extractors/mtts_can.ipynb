{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MTTS-CAN\n",
    "\n",
    "This notebook demonstrates how to extract respiration and pulse from a video using the MTTS-CAN model."
   ],
   "id": "b6ba6bc45797825"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "\n",
    "subject = 'Proband05'\n",
    "setting = '101_natural_lighting'"
   ],
   "id": "4b78c47457679ff0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frames, meta = dataset.get_video_rgb(\n",
    "    subject,\n",
    "    setting,\n",
    "    num_frames=30 * 10,\n",
    "    show_progress=True,\n",
    ")"
   ],
   "id": "6346cc5fba0f739b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "\n",
    "The MTTS-CAN model expects the frames to be resized and normalized in the temporal domain."
   ],
   "id": "8f935dd1b0a8cd84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.extractor.mtts_can import (\n",
    "    preprocess_video_frames,\n",
    "    preprocess_frames_original,\n",
    ")\n",
    "\n",
    "# resized, normalized = preprocess_frames_original(frames)\n",
    "resized, normalized = preprocess_video_frames(frames)"
   ],
   "id": "a0e809ccc33cb75d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import respiration.utils as utils\n",
    "\n",
    "# Plot resized and normalized frames\n",
    "_, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axs[0].imshow(resized[1])\n",
    "axs[0].set_title('Resized Frame')\n",
    "\n",
    "axs[1].imshow(normalized[1])\n",
    "axs[1].set_title('Normalized Frame')\n",
    "\n",
    "figure_dir = utils.dir_path('outputs', 'figures', 'pre-process', mkdir=True)\n",
    "utils.savefig(plt.gcf(), figure_dir, 'mtts_can')"
   ],
   "id": "bf07951fc37c8fbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prediction",
   "id": "db534c478d422922"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from respiration.extractor.mtts_can import load_model\n",
    "\n",
    "frame_depth = 10\n",
    "\n",
    "# The model expects a number of frames that is a multiple of frame_depth\n",
    "cut_off = (normalized.shape[0] // frame_depth) * frame_depth\n",
    "input_resized = resized[:cut_off]\n",
    "input_normalized = normalized[:cut_off]"
   ],
   "id": "bd3a9cecac6fa1f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = load_model()\n",
    "predictions = model.predict(\n",
    "    (input_resized, input_normalized),\n",
    "    batch_size=100\n",
    ")"
   ],
   "id": "b1335ca57c4ddcd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "pulse_prediction = np.cumsum(predictions[0])\n",
    "respiration_prediction = np.cumsum(predictions[1])"
   ],
   "id": "276e66603862052f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Show the predicted pulse",
   "id": "11d60331ee7aadc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.utils as utils\n",
    "import respiration.analysis as analysis\n",
    "\n",
    "pulse_gt = dataset.get_vital_sign(subject, setting, utils.VitalSigns.pulse)\n",
    "\n",
    "# Not all frames are used for prediction --> cut the ground truth to the same length\n",
    "pulse_gt = pulse_gt[:pulse_prediction.shape[0]]\n",
    "\n",
    "pulse_compare = analysis.SignalCompare(\n",
    "    pulse_prediction,\n",
    "    pulse_gt,\n",
    "    meta.fps,\n",
    "    lowpass=0.75,\n",
    "    highpass=2.5,\n",
    ")"
   ],
   "id": "74501793ce2154e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pulse_compare.bpm_errors()",
   "id": "7fbb9a803e8343ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pulse_compare.distances()",
   "id": "72d1abdea7e14253",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the pulse prediction\n",
    "_ = plt.figure(figsize=(20, 10))\n",
    "plt.plot(pulse_compare.prediction, label='Pulse Prediction')\n",
    "plt.plot(pulse_compare.ground_truth, label='Pulse Ground Truth')\n",
    "plt.title('Pulse Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Pulse')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "a2cc1f0a48d23214",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Show the predicted respiration",
   "id": "6da13d360536ca3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "respiration_gt = dataset.get_breathing_signal(subject, setting)\n",
    "\n",
    "# Not all frames are used for prediction --> cut the ground truth to the same length\n",
    "respiration_gt = respiration_gt[:respiration_prediction.shape[0]]\n",
    "\n",
    "pulse_compare = analysis.SignalCompare(\n",
    "    pulse_prediction,\n",
    "    respiration_prediction,\n",
    "    meta.fps,\n",
    "    lowpass=0.75,\n",
    "    highpass=2.5,\n",
    ")"
   ],
   "id": "42ef3a0638f024f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pulse_compare.bpm_errors()",
   "id": "e41eec9f5e8a4dff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pulse_compare.distances()",
   "id": "6b0818a024ff8ca9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the respiration prediction\n",
    "_ = plt.figure(figsize=(20, 10))\n",
    "plt.plot(pulse_compare.prediction, label='Respiration Prediction')\n",
    "plt.plot(pulse_compare.ground_truth, label='Respiration Ground Truth')\n",
    "plt.title('Respiration Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Respiration')"
   ],
   "id": "9150a613bec85c6d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
