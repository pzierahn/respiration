{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extracting Respiration Signals with Face Transformer\n",
    "\n",
    "This notebook creates predictions of respiratory signals for all models trained with the face transformer architecture."
   ],
   "id": "344c1b3a21abce83"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import respiration.utils as utils\n",
    "\n",
    "model_ids = [\n",
    "    # '20240710_142159',\n",
    "    # '20240710_194632',\n",
    "    # '20240710_220756',\n",
    "    # '20240711_194917',\n",
    "    # '20240712_113946',\n",
    "    # '20240712_163619',\n",
    "    # '20240713_090928',\n",
    "    '20240728_114332',\n",
    "    '20240728_172805',\n",
    "    '20240729_195756',\n",
    "    '20240803_105616',\n",
    "    '20240821_115511',\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "device = utils.get_torch_device()",
   "id": "10c9d9e53a3e5a58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from vit_pytorch import SimpleViT\n",
    "\n",
    "\n",
    "def load_model(model_id: str) -> (SimpleViT, dict):\n",
    "    model_dir = utils.dir_path('models', 'transformer', model_id)\n",
    "    manifest_path = utils.join_paths(model_dir, 'manifest.json')\n",
    "    manifest = utils.read_json(manifest_path)\n",
    "\n",
    "    model = SimpleViT(\n",
    "        image_size=manifest['image_size'],\n",
    "        patch_size=manifest['image_patch_size'],\n",
    "        num_classes=1,\n",
    "        dim=manifest['embedding_dim'],\n",
    "        heads=manifest['heads'],\n",
    "        mlp_dim=manifest['mlp_dim'],\n",
    "        depth=manifest['depth'],\n",
    "    ).to(device)\n",
    "\n",
    "    # Load the best model from the training process\n",
    "    model_path = utils.join_paths(model_dir, manifest['trained_models'][-1]['model'])\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return model, manifest"
   ],
   "id": "b432d6405d662fba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "from respiration.training import ScenarioLoader\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for model_id in tqdm(model_ids):\n",
    "    model, manifest = load_model(model_id)\n",
    "    scenarios = manifest['testing_scenarios']\n",
    "\n",
    "    image_dim = (256, 256)\n",
    "\n",
    "    for inx, (subject, setting) in enumerate(scenarios):\n",
    "        print(f'Processing {subject} - {setting}')\n",
    "        num_frames = manifest['num_frames'] if 'num_frames' in manifest else 300\n",
    "        loader = ScenarioLoader(subject, setting, num_frames, device)\n",
    "\n",
    "        prediction = []\n",
    "\n",
    "        for (frames, gt_classes) in loader:\n",
    "            frames = utils.preprocess_frames(frames, image_dim, device).squeeze()\n",
    "            # Disable gradient computation and reduce memory consumption.\n",
    "            with torch.no_grad():\n",
    "                outputs = model(frames).squeeze()\n",
    "            prediction.extend(outputs.tolist())\n",
    "\n",
    "        predictions.append({\n",
    "            'subject': subject,\n",
    "            'setting': setting,\n",
    "            'model': model_id,\n",
    "            'signal': prediction,\n",
    "        })"
   ],
   "id": "9cd0754594965f72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(predictions)\n",
    "\n",
    "output_dir = utils.dir_path('outputs', 'signals', mkdir=True)\n",
    "\n",
    "# Save the evaluation dataframe\n",
    "csv_path = utils.join_paths(output_dir, 'transformer_predictions.csv')\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "df.head()"
   ],
   "id": "7e3d941678abefce",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
