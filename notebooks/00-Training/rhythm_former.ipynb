{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train Rhythm Former\n",
    "\n",
    "This notebook trains and fine-tunes the Rhythm Former model on the VitalCam dataset."
   ],
   "id": "4c8a3ac7b2973e9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.utils as utils\n",
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "meta_manifest = {}\n",
    "\n",
    "split_ratio = 0.8\n",
    "meta_manifest['split_ratio'] = split_ratio\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "\n",
    "device = utils.get_torch_device()\n",
    "meta_manifest['device'] = device\n",
    "\n",
    "epochs = 22\n",
    "meta_manifest['epochs'] = epochs\n",
    "\n",
    "min_freq = 0.1\n",
    "meta_manifest['min_freq'] = min_freq\n",
    "\n",
    "max_freq = 0.5\n",
    "meta_manifest['max_freq'] = max_freq\n",
    "\n",
    "learning_rate = 0.009\n",
    "meta_manifest['learning_rate'] = learning_rate\n",
    "\n",
    "meta_manifest['model'] = 'RhythmFormer'"
   ],
   "id": "a986fa7a5e5415b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "configurations = [\n",
    "    {\n",
    "        'image_size': (128, 128),\n",
    "        'split': 5,\n",
    "        'pearson_weight': 1.0,\n",
    "        'frequency_weight': 1.0,\n",
    "        'norm_weight': 0.0,\n",
    "        'mse_weight': 1.0,\n",
    "        'spectral_convergence_weight': 1.0,\n",
    "        'spectral_magnitude_weight': 1.0,\n",
    "        'spectral_magnitude_norm': 'L1',\n",
    "        'setting': '101_natural_lighting',\n",
    "    },\n",
    "    {\n",
    "        'image_size': (128, 128),\n",
    "        'split': 5,\n",
    "        'pearson_weight': 1.0,\n",
    "        'frequency_weight': 1.0,\n",
    "        'norm_weight': 0.0,\n",
    "        'mse_weight': 1.0,\n",
    "        'spectral_convergence_weight': 1.0,\n",
    "        'spectral_magnitude_weight': 1.0,\n",
    "        'spectral_magnitude_norm': 'L1',\n",
    "        'setting': '303_normalized_face',\n",
    "    },\n",
    "    {\n",
    "        'image_size': (128, 128),\n",
    "        'split': 5,\n",
    "        'pearson_weight': 0.0,\n",
    "        'frequency_weight': 0.0,\n",
    "        'norm_weight': 1.0,\n",
    "        'mse_weight': 0.0,\n",
    "        'spectral_convergence_weight': 1.0,\n",
    "        'spectral_magnitude_weight': 1.0,\n",
    "        'spectral_magnitude_norm': 'L1',\n",
    "        'setting': '101_natural_lighting',\n",
    "    },\n",
    "]"
   ],
   "id": "f2b2ccf3f1ae282a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "\n",
    "from respiration.training import HybridLoss\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from respiration.extractor.rhythm_former import RhythmFormer\n",
    "from respiration.training import VitalCamLoader\n",
    "\n",
    "for config in configurations:\n",
    "\n",
    "    manifest = meta_manifest.copy()\n",
    "    image_size = config['image_size']\n",
    "\n",
    "    # The timestamp is the unique identifier for this training run\n",
    "    zone = timezone('Europe/Berlin')\n",
    "    timestamp = datetime.now().astimezone(zone).strftime('%Y%m%d_%H%M%S')\n",
    "    manifest['timestamp'] = timestamp\n",
    "    manifest['config'] = config\n",
    "    manifest['start_time'] = datetime.now().isoformat()\n",
    "    manifest['image_size'] = image_size\n",
    "\n",
    "    print('timestamp:', timestamp)\n",
    "\n",
    "    loss_fn = HybridLoss(\n",
    "        min_freq=min_freq,\n",
    "        max_freq=max_freq,\n",
    "        pearson_weight=config['pearson_weight'],\n",
    "        frequency_weight=config['frequency_weight'],\n",
    "        norm_weight=config['norm_weight'],\n",
    "        mse_weight=config['mse_weight'],\n",
    "        spectral_convergence_weight=config['spectral_convergence_weight'],\n",
    "        spectral_magnitude_weight=config['spectral_magnitude_weight'],\n",
    "    )\n",
    "    manifest['loss_fn'] = 'HybridLoss'\n",
    "\n",
    "    manifest['loss_fn_config'] = loss_fn.get_config()\n",
    "\n",
    "    model = RhythmFormer(\n",
    "        image_size=image_size,\n",
    "    )\n",
    "    # Fix model loading: Some key have an extra 'module.' prefix\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    manifest['optimizer'] = 'Adam'\n",
    "\n",
    "    model_dir = utils.dir_path(\n",
    "        'models',\n",
    "        'rhythm_former_v2',\n",
    "        timestamp,\n",
    "        mkdir=True)\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    manifest['models'] = []\n",
    "    manifest['losses'] = []\n",
    "\n",
    "    # The split size heavenly influences the frequency resolution of the PSD in the loss function.\n",
    "    # The smaller the split size, the higher the frequency resolution. However, the GPU memory for training\n",
    "    # is limited. There is a trade-off between frequency resolution, memory consumption and image size.\n",
    "    # Split 5:  Step size 0.04 Hz (1.25 BPM)\n",
    "    # Split 10: Step size 0.08 Hz (2.50 BPM)\n",
    "    split = config['split']\n",
    "    manifest['split'] = split\n",
    "\n",
    "    scenarios_all = dataset.get_scenarios([config['setting']])\n",
    "\n",
    "    training = scenarios_all[:int(len(scenarios_all) * split_ratio)]\n",
    "    manifest['training_scenarios'] = training\n",
    "\n",
    "    testing = scenarios_all[int(len(scenarios_all) * split_ratio):]\n",
    "    manifest['testing_scenarios'] = testing\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        training_loader = VitalCamLoader(training, split=split, device=device)\n",
    "        testing_loader = VitalCamLoader(testing, split=split, device=device)\n",
    "\n",
    "        train_loss = 0\n",
    "        for (frames, target) in tqdm(training_loader, desc=f'Training'):\n",
    "            frames = utils.preprocess_frames(frames, image_size, device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(frames).squeeze(0)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(output, target)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            del frames, target, output, loss\n",
    "\n",
    "        testing_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (frames, target) in tqdm(testing_loader, desc=f'Testing'):\n",
    "                frames = utils.preprocess_frames(frames, image_size, device)\n",
    "\n",
    "                output = model(frames).squeeze(0)\n",
    "\n",
    "                loss = loss_fn(output, target)\n",
    "                testing_loss += loss.item()\n",
    "\n",
    "                del frames, target, output, loss\n",
    "\n",
    "        # Compute the average loss\n",
    "        train_loss /= len(training_loader)\n",
    "        testing_loss /= len(testing_loader)\n",
    "\n",
    "        if testing_loss < best_loss:\n",
    "            best_loss = testing_loss\n",
    "            model_file = utils.file_path(model_dir, f'RF_{epoch}.pth')\n",
    "\n",
    "            manifest['best_loss'] = best_loss\n",
    "            manifest['models'].append({\n",
    "                'epoch': epoch,\n",
    "                'model_file': model_file,\n",
    "                'train_loss': train_loss,\n",
    "                'test_loss': testing_loss,\n",
    "            })\n",
    "\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "\n",
    "        print(f'[{epoch + 1}/{epochs}] '\n",
    "              f'train-loss={train_loss:.3f} '\n",
    "              f'test-loss={testing_loss:.3f}')\n",
    "        manifest['losses'].append({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'test_loss': testing_loss,\n",
    "        })\n",
    "\n",
    "        # Save the manifest\n",
    "        manifest['epoch'] = epoch\n",
    "        manifest['end_time'] = datetime.now().isoformat()\n",
    "        manifest_file = utils.file_path(model_dir, 'manifest.json')\n",
    "        utils.write_json(manifest_file, manifest)"
   ],
   "id": "a2e8a777bc0c7a3d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
