{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Transformer Classifier\n",
    "\n",
    "This notebook trains a Transformer based classifier to predict inhaling and exhaling from video frames."
   ],
   "id": "67dc06081e64a18c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import respiration.utils as utils\n",
    "\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "\n",
    "# The timestamp is the unique identifier for this training run\n",
    "zone = timezone('Europe/Berlin')\n",
    "model_id = datetime.now().astimezone(zone).strftime('%Y%m%d_%H%M%S')\n",
    "device = utils.get_torch_device()\n",
    "\n",
    "# The manifest will store all the metadata for this training run\n",
    "manifest = {\n",
    "    'id': model_id,\n",
    "    'device': str(device),\n",
    "    'timestamp_start': datetime.now().astimezone().isoformat(),\n",
    "    'dataset': 'VitalCamSet',\n",
    "}\n",
    "model_id"
   ],
   "id": "be65cae3ecad860b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "device",
   "id": "4df3cafeef133826",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define training and testing scenarios",
   "id": "a34c6df561579356"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.dataset import VitalCamSet\n",
    "\n",
    "dataset = VitalCamSet()\n",
    "scenarios_all = dataset.get_scenarios(['303_normalized_face'])\n",
    "\n",
    "split_ratio = 0.8\n",
    "manifest['split_ratio'] = split_ratio\n",
    "\n",
    "training = scenarios_all[:int(len(scenarios_all) * split_ratio)]\n",
    "manifest['training_scenarios'] = training\n",
    "\n",
    "testing = scenarios_all[int(len(scenarios_all) * split_ratio):]\n",
    "manifest['testing_scenarios'] = testing"
   ],
   "id": "a7a49d6cd0a17760",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_frames = 300\n",
    "manifest['num_frames'] = num_frames"
   ],
   "id": "92b4df33dcf3161",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define temporal shifting",
   "id": "6cf51af626d8711"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_size = 128\n",
    "manifest['image_size'] = image_size"
   ],
   "id": "6045eb1b0069b2bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test the ScenarioLoader",
   "id": "157cbbbee85c69ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from respiration.training import ScenarioLoader\n",
    "\n",
    "loader = ScenarioLoader('Proband22', '303_normalized_face', num_frames, device)\n",
    "chunk_frames, chunk_signal = loader[4]\n",
    "chunk_frames.shape, chunk_signal.shape"
   ],
   "id": "39481a906bbf2d91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Training",
   "id": "1cccdc3abd23e9a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "log_dir = utils.dir_path('outputs', 'logs', model_id, mkdir=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ],
   "id": "8c815980f7431cb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from vit_pytorch import SimpleViT\n",
    "\n",
    "image_patch_size = 16\n",
    "manifest['image_patch_size'] = image_patch_size\n",
    "\n",
    "depth = 12\n",
    "manifest['depth'] = depth\n",
    "\n",
    "heads = 12\n",
    "manifest['heads'] = heads\n",
    "\n",
    "embedding_dim = 256\n",
    "manifest['embedding_dim'] = embedding_dim\n",
    "\n",
    "mlp_dim = embedding_dim * 4\n",
    "manifest['mlp_dim'] = mlp_dim\n",
    "\n",
    "num_classes = 1\n",
    "manifest['num_classes'] = num_classes\n",
    "\n",
    "model = SimpleViT(\n",
    "    image_size=image_size,\n",
    "    patch_size=image_patch_size,\n",
    "    num_classes=num_classes,\n",
    "    dim=embedding_dim,\n",
    "    heads=heads,\n",
    "    mlp_dim=mlp_dim,\n",
    "    depth=depth,\n",
    ").to(device)\n",
    "manifest['base_model'] = 'simple_vit'"
   ],
   "id": "bcc71511f5183e9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from respiration.training import HybridLoss\n",
    "\n",
    "epochs = 30\n",
    "manifest['epochs'] = epochs\n",
    "\n",
    "learning_rate = 0.00001\n",
    "manifest['learning_rate'] = learning_rate\n",
    "\n",
    "loss_fn = HybridLoss()\n",
    "manifest['loss_fn'] = 'HybridLoss'\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "manifest['optimizer'] = 'AdamW'"
   ],
   "id": "1f16e5efdceab177",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def preprocess_frames(frames):\n",
    "    # Preprocess the frames to be in 128x128 with torch\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(mode='RGB'),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Transform each frame\n",
    "    transformed_frames = torch.stack([\n",
    "        transform(frame) for frame in frames\n",
    "    ])\n",
    "\n",
    "    return transformed_frames.unsqueeze(0).to(device)"
   ],
   "id": "d58335934adea42a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_one_epoch(epoch_index: int):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    # Iterate over the training scenarios\n",
    "    for (subject, setting) in training:\n",
    "        loader = ScenarioLoader(subject, setting, num_frames, device)\n",
    "\n",
    "        scenario_loss = 0.0\n",
    "\n",
    "        # Iterate over the hole scenario video in chunks\n",
    "        for idy, (frames, gt_classes) in enumerate(loader):\n",
    "            frames = preprocess_frames(frames)\n",
    "\n",
    "            # Make predictions for this chunk\n",
    "            outputs = model(frames).squeeze()\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            loss = loss_fn(outputs, gt_classes)\n",
    "\n",
    "            # Optimize the model\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Gather data and report\n",
    "            print(f'  {subject} #{idy:02d} loss={loss.item()}')\n",
    "            scenario_loss += loss.item()\n",
    "\n",
    "        scenario_loss /= len(loader)\n",
    "        epoch_loss += scenario_loss\n",
    "\n",
    "        print(f'  >> {subject} scenario_loss={scenario_loss}')\n",
    "        writer.add_scalars('Training_Loss', {\n",
    "            f'{subject}_{setting}': scenario_loss,\n",
    "        }, epoch_index)\n",
    "        writer.flush()\n",
    "\n",
    "    return epoch_loss / len(training)"
   ],
   "id": "c5f12b4ed685e672",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_dir = utils.dir_path('models', 'transformer', model_id, mkdir=True)",
   "id": "bddc7e7fbb29988",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "models = []\n",
    "best_loss = float('inf')"
   ],
   "id": "caf9abb654eebf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_manifest():\n",
    "    manifest['trained_models'] = models\n",
    "    manifest['best_testing_loss'] = float(best_loss)\n",
    "    manifest['timestamp_finish'] = datetime.now().astimezone().isoformat()\n",
    "    utils.write_json(os.path.join(model_dir, 'manifest.json'), manifest)"
   ],
   "id": "7e66bf39b3816485",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f'Epoch {epoch}:')\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for inx, (subject, setting) in enumerate(testing):\n",
    "            loader = ScenarioLoader(subject, setting, num_frames, device)\n",
    "            testing_loss = 0.0\n",
    "\n",
    "            for (frames, gt_classes) in loader:\n",
    "                frames = preprocess_frames(frames)\n",
    "                voutputs = model(frames).squeeze()\n",
    "                testing_loss += loss_fn(voutputs, gt_classes).item()\n",
    "\n",
    "            testing_loss /= len(loader)\n",
    "            writer.add_scalars('Testing_Loss', {f'{subject}_{setting}': testing_loss}, epoch)\n",
    "            print(f'  >> {subject} loss={testing_loss}')\n",
    "\n",
    "            running_loss += testing_loss\n",
    "\n",
    "    testing_loss = running_loss / len(testing)\n",
    "    print(f'LOSS training={avg_loss} testing={testing_loss}')\n",
    "    writer.add_scalars('Average_Loss', {\n",
    "        'Training': avg_loss,\n",
    "        'Testing': testing_loss,\n",
    "    }, epoch)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track the best performance, and save the model's state\n",
    "    if testing_loss < best_loss:\n",
    "        best_loss = testing_loss\n",
    "        model_name = f'{model_id}_{epoch}.pth'\n",
    "\n",
    "        model_path = os.path.join(model_dir, model_name)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        models.append({\n",
    "            'model': model_name,\n",
    "            'epoch': epoch,\n",
    "            'validation_loss': float(testing_loss),\n",
    "        })\n",
    "        save_manifest()"
   ],
   "id": "63f1645676dd1690",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save_manifest()",
   "id": "7c44122f4d4d4657",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
